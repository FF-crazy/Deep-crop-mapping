{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Swin Transformer 农作物制图训练和评估\\n\\n本notebook演示如何使用Swin Transformer模型进行多光谱时序数据的农作物分类任务。Swin Transformer采用层次化设计和移位窗口注意力机制，在保持高精度的同时实现了线性计算复杂度。\\n\\n## 🔄 双模式设计\\n\\n**📋 本notebook支持两种运行模式：**\\n\\n### 🧪 TEST模式 \\n- **目的**: 本地快速测试代码正确性\\n- **配置**: 轻量级模型，小数据集，少量epochs\\n- **用时**: ~3分钟\\n- **适用**: 开发调试，验证代码逻辑\\n- **环境**: 本地CPU/GPU，低内存要求\\n\\n### 🚀 TRAIN模式\\n- **目的**: 云端GPU完整训练获得最佳性能\\n- **配置**: 标准模型，完整数据集，完整epochs\\n- **用时**: ~8-16小时\\n- **适用**: 正式训练，获得部署模型\\n- **环境**: 云端GPU，高性能要求\\n\\n**💡 使用建议：**\\n1. 本地开发时使用TEST模式验证代码\\n2. 确认无误后切换到TRAIN模式进行完整训练\\n3. 在云端GPU上运行TRAIN模式以获得最佳效果\\n\\n---\\n\\n## 目录\\n1. [运行模式配置](#运行模式配置)\\n2. [环境设置和导入](#环境设置和导入)\\n3. [数据加载和探索](#数据加载和探索)\\n4. [模型创建和配置](#模型创建和配置)\\n5. [训练过程](#训练过程)\\n6. [模型评估](#模型评估)\\n7. [结果可视化](#结果可视化)\\n8. [窗口注意力分析](#窗口注意力分析)\\n9. [模型推理](#模型推理)\"",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 🔧 运行模式配置\n# 设置 RUNNING_MODE 来选择运行模式\n# - \"TEST\": 本地测试模式，快速验证代码正确性\n# - \"TRAIN\": 云端训练模式，完整训练流程\n\nRUNNING_MODE = \"TEST\"  # 👈 修改这里来切换模式: \"TEST\" 或 \"TRAIN\"\n\nprint(f\"🔄 当前运行模式: {RUNNING_MODE}\")\n\nif RUNNING_MODE == \"TEST\":\n    print(\"🧪 TEST模式 - 用于本地测试:\")\n    print(\"  ✓ 使用小数据集\")\n    print(\"  ✓ 快速训练 (5 epochs)\")\n    print(\"  ✓ 小模型配置\")\n    print(\"  ✓ 快速验证代码正确性\")\nelif RUNNING_MODE == \"TRAIN\":\n    print(\"🚀 TRAIN模式 - 用于云端GPU训练:\")\n    print(\"  ✓ 使用完整数据集\")\n    print(\"  ✓ 完整训练 (50+ epochs)\")\n    print(\"  ✓ 标准模型配置\")\n    print(\"  ✓ 最佳性能优化\")\nelse:\n    raise ValueError(\"RUNNING_MODE 必须是 'TEST' 或 'TRAIN'\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. 运行模式配置\n\n选择运行模式来适配不同的使用场景：\n- **TEST模式**：快速验证代码正确性，适合本地开发\n- **TRAIN模式**：完整训练流程，适合云端GPU训练",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin Transformer 农作物制图训练和评估\n",
    "\n",
    "本notebook演示如何使用Swin Transformer模型进行多光谱时序数据的农作物分类任务。Swin Transformer采用层次化设计和移位窗口注意力机制，在保持高精度的同时实现了线性计算复杂度。\n",
    "\n",
    "## 目录\n",
    "1. [环境设置和导入](#环境设置和导入)\n",
    "2. [数据加载和探索](#数据加载和探索)\n",
    "3. [模型创建和配置](#模型创建和配置)\n",
    "4. [训练过程](#训练过程)\n",
    "5. [模型评估](#模型评估)\n",
    "6. [结果可视化](#结果可视化)\n",
    "7. [窗口注意力分析](#窗口注意力分析)\n",
    "8. [模型推理](#模型推理)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 检查是否有einops库（Swin Transformer需要）\n",
    "try:\n",
    "    import einops\n",
    "    print(\"✓ einops available\")\n",
    "except ImportError:\n",
    "    print(\"❌ einops not found. Please install: pip install einops\")\n",
    "\n",
    "# 设置matplotlib中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU设备: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入Swin Transformer模块\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from model import create_swin_model, CropMappingSwinTransformer\n",
    "from dataset import prepare_data, save_data_info, load_data_info\n",
    "from train import (\n",
    "    train_epoch, validate, FocalLoss, DiceLoss, CombinedLoss\n",
    ")\n",
    "from utils import (\n",
    "    save_checkpoint, load_checkpoint, EarlyStopping,\n",
    "    calculate_metrics, plot_training_history, plot_class_performance,\n",
    "    plot_confusion_matrix, visualize_predictions, plot_window_attention\n",
    ")\n",
    "\n",
    "print(\"✅ Swin Transformer模块导入成功!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载和探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 📋 根据运行模式配置参数\nif RUNNING_MODE == \"TEST\":\n    # 🧪 TEST模式配置 - 快速测试代码正确性\n    config = {\n        # 数据参数 - 使用更小的数据量\n        'data_path': '../dataset',\n        'patch_size': 32,     # 更小的patch大小\n        'stride': 16,         # 更小的stride，减少数据量\n        'test_size': 0.3,     # 更大的测试集比例\n        'val_size': 0.2,      # 更大的验证集比例\n        'batch_size': 2,      # 小batch size用于测试\n        'num_workers': 2,     # 少量工作进程\n        \n        # 模型参数 - 轻量级配置\n        'input_channels': 8,\n        'temporal_steps': 28,\n        'swin_patch_size': 4,\n        'embed_dim': 48,      # 更小的嵌入维度\n        'depths': [1, 1, 2, 1],  # 更浅的网络\n        'num_heads': [2, 4, 8, 16],  # 更少的注意力头\n        'window_size': 4,     # 更小的窗口\n        'mlp_ratio': 2.0,     # 更小的MLP比例\n        'dropout': 0.0,\n        'attn_dropout': 0.0,\n        'drop_path_rate': 0.05,\n        \n        # 训练参数 - 快速训练\n        'epochs': 5,          # 很少的epochs用于测试\n        'learning_rate': 1e-3, # 稍大的学习率快速收敛\n        'weight_decay': 0.01,\n        'gradient_accumulation_steps': 1,\n        'max_grad_norm': 1.0,\n        \n        # 损失函数\n        'use_combined_loss': False,  # 简单损失函数\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.05,\n        \n        # 学习率调度\n        'scheduler_type': 'none',  # 不使用调度器\n        'min_lr': 1e-5,\n        \n        # 其他\n        'patience': 5,        # 短耐心值\n        'save_dir': '../Models/swin-transformer/test',  # 修改输出路径\n        'augment_train': False  # 不使用数据增强\n    }\n    print(\"🧪 使用TEST模式配置 - 适合快速验证代码\")\n    \nelif RUNNING_MODE == \"TRAIN\":\n    # 🚀 TRAIN模式配置 - 完整训练流程\n    config = {\n        # 数据参数 - 使用完整数据集\n        'data_path': '../dataset',\n        'patch_size': 64,     # 标准patch大小\n        'stride': 32,         # 标准stride\n        'test_size': 0.2,\n        'val_size': 0.1,\n        'batch_size': 8,      # 适中的batch size\n        'num_workers': 4,\n        \n        # 模型参数 - 标准配置\n        'input_channels': 8,\n        'temporal_steps': 28,\n        'swin_patch_size': 4,\n        'embed_dim': 96,      # 标准嵌入维度\n        'depths': [2, 2, 6, 2],  # 标准深度\n        'num_heads': [3, 6, 12, 24],  # 标准注意力头数\n        'window_size': 7,     # 标准窗口大小\n        'mlp_ratio': 4.0,\n        'dropout': 0.0,\n        'attn_dropout': 0.0,\n        'drop_path_rate': 0.1,\n        \n        # 训练参数 - 完整训练\n        'epochs': 100,        # 完整训练轮数\n        'learning_rate': 1e-4, # 标准学习率\n        'weight_decay': 0.05, # Swin推荐的权重衰减\n        'gradient_accumulation_steps': 2,\n        'max_grad_norm': 5.0,\n        \n        # 损失函数\n        'use_combined_loss': True,  # 使用组合损失\n        'focal_gamma': 2.5,\n        'label_smoothing': 0.1,\n        \n        # 学习率调度\n        'scheduler_type': 'cosine',\n        'min_lr': 1e-6,\n        \n        # 其他\n        'patience': 15,       # 长耐心值\n        'save_dir': '../Models/swin-transformer/train',  # 修改输出路径\n        'augment_train': True  # 使用数据增强\n    }\n    print(\"🚀 使用TRAIN模式配置 - 适合完整训练\")\n\n# 创建保存目录\nPath(config['save_dir']).mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\n📋 当前配置 ({RUNNING_MODE}模式):\")\nfor key, value in config.items():\n    print(f\"  {key}: {value}\")\n\nif RUNNING_MODE == \"TEST\":\n    print(\"\\n⚠️ 注意: TEST模式使用简化配置，仅用于验证代码正确性!\")\nelse:\n    print(\"\\n💪 TRAIN模式: 使用完整配置进行最佳性能训练!\")\n\nprint(f\"\\n💾 模型输出目录: {config['save_dir']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🔄 加载和准备数据（适配不同模式）\nprint(f\\\"🔄 加载数据 ({RUNNING_MODE}模式)...\\\")\\n\\ntrain_loader, val_loader, test_loader, data_info = prepare_data(\\n    data_path=config['data_path'],\\n    patch_size=config['patch_size'],\\n    stride=config['stride'],\\n    test_size=config['test_size'],\\n    val_size=config['val_size'],\\n    batch_size=config['batch_size'],\\n    num_workers=config['num_workers'],\\n    augment_train=config['augment_train'],\\n    swin_patch_size=config['swin_patch_size']\\n)\\n\\nprint(f\\\"\\\\n📊 数据集信息 ({RUNNING_MODE}模式):\\\")\\nprint(f\\\"  类别数量: {data_info['num_classes']}\\\")\\nprint(f\\\"  训练批次: {len(train_loader)}\\\")\\nprint(f\\\"  验证批次: {len(val_loader)}\\\")\\nprint(f\\\"  测试批次: {len(test_loader)}\\\")\\nprint(f\\\"  调整后patch大小: {data_info['patch_size']}\\\")\\nprint(f\\\"  Swin patch大小: {data_info['swin_patch_size']}\\\")\\nprint(f\\\"  输入形状: {data_info['input_shape']}\\\")\\n\\n# 估算数据量\\ntotal_train_samples = len(train_loader) * config['batch_size']\\ntotal_val_samples = len(val_loader) * config['batch_size']\\nprint(f\\\"  训练样本数: ~{total_train_samples}\\\")\\nprint(f\\\"  验证样本数: ~{total_val_samples}\\\")\\n\\nif RUNNING_MODE == \\\"TEST\\\":\\n    print(f\\\"\\\\n🧪 TEST模式数据量: 使用小数据集快速测试\\\")\\n    print(f\\\"  预计单epoch时间: ~30秒\\\")\\n    print(f\\\"  总训练时间: ~3分钟\\\")\\nelse:\\n    print(f\\\"\\\\n🚀 TRAIN模式数据量: 使用完整数据集\\\")\\n    print(f\\\"  预计单epoch时间: ~5-10分钟\\\")\\n    print(f\\\"  总训练时间: ~8-16小时\\\")\\n\\n# 保存数据信息\\nsave_data_info(data_info, f\\\"{config['save_dir']}/data_info.pkl\\\")\\n\\n# 显示类别信息\\nprint(f\\\"\\\\n🏷️ 类别信息:\\\")\\nfor idx, name in data_info['class_names'].items():\\n    print(f\\\"  {idx}: {name}\\\")\\n\\nprint(f\\\"\\\\n⚖️ 类别权重: {data_info['class_weights'].numpy()}\\\")\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 📊 数据可视化（适配不同模式）\\n# 获取一个批次的数据进行可视化\\ndata_iter = iter(train_loader)\\nsample_batch_x, sample_batch_y = next(data_iter)\\n\\nprint(f\\\"样本批次形状 - X: {sample_batch_x.shape}, Y: {sample_batch_y.shape}\\\")\\nprint(f\\\"X数值范围: [{sample_batch_x.min():.3f}, {sample_batch_x.max():.3f}]\\\")\\nprint(f\\\"Y唯一值: {torch.unique(sample_batch_y)}\\\")\\n\\n# 根据模式决定可视化样本数量\\nif RUNNING_MODE == \\\"TEST\\\":\\n    num_samples = min(4, sample_batch_x.shape[0])  # TEST模式显示更少样本\\n    print(f\\\"\\\\n🧪 TEST模式: 显示 {num_samples} 个样本进行快速验证\\\")\\nelse:\\n    num_samples = min(8, sample_batch_x.shape[0])  # TRAIN模式显示更多样本\\n    print(f\\\"\\\\n🚀 TRAIN模式: 显示 {num_samples} 个样本进行详细分析\\\")\\n\\n# 可视化RGB样本\\nrows = 2 if num_samples > 4 else 1\\ncols = min(4, num_samples)\\nfig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\\nfig.suptitle(f'Swin Transformer Input Samples - RGB Visualization ({RUNNING_MODE} Mode)', fontsize=16)\\n\\nif rows == 1:\\n    axes = axes if num_samples > 1 else [axes]\\nelse:\\n    axes = axes.ravel()\\n\\nfor i in range(num_samples):\\n    # 显示第一个时间步的RGB合成图像\\n    rgb_img = sample_batch_x[i, :, :, 0, :3].numpy()\\n    rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\\n    \\n    ax_idx = i if rows == 1 else i\\n    axes[ax_idx].imshow(rgb_img)\\n    axes[ax_idx].set_title(f'Sample {i+1} - RGB (t=0)')\\n    axes[ax_idx].axis('off')\\n\\nplt.tight_layout()\\nplt.show()\\n\\n# 可视化对应的标签\\nfig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\\nfig.suptitle(f'Ground Truth Labels ({RUNNING_MODE} Mode)', fontsize=16)\\n\\nif rows == 1:\\n    axes = axes if num_samples > 1 else [axes]\\nelse:\\n    axes = axes.ravel()\\n\\nfor i in range(num_samples):\\n    ax_idx = i if rows == 1 else i\\n    im = axes[ax_idx].imshow(sample_batch_y[i].numpy(), cmap='tab10', vmin=0, vmax=7)\\n    axes[ax_idx].set_title(f'Sample {i+1} - Labels')\\n    axes[ax_idx].axis('off')\\n\\nplt.tight_layout()\\nplt.show()\\n\\nif RUNNING_MODE == \\\"TEST\\\":\\n    print(\\\"✓ 数据加载测试完成，代码运行正常!\\\")\\nelse:\\n    print(\\\"✓ 数据加载完成，准备开始完整训练!\\\")\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型创建和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"🖥️ 使用设备: {device}\")\n",
    "\n",
    "# 创建Swin Transformer模型\n",
    "model = create_swin_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['swin_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    depths=config['depths'],\n",
    "    num_heads=config['num_heads'],\n",
    "    window_size=config['window_size'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    drop_rate=config['dropout'],\n",
    "    attn_drop_rate=config['attn_dropout'],\n",
    "    drop_path_rate=config['drop_path_rate']\n",
    ").to(device)\n",
    "\n",
    "# 计算参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n🔧 Swin Transformer模型信息:\")\n",
    "print(f\"  总参数量: {total_params:,}\")\n",
    "print(f\"  可训练参数: {trainable_params:,}\")\n",
    "print(f\"  模型大小: {total_params * 4 / (1024**2):.1f} MB (FP32)\")\n",
    "print(f\"  嵌入维度: {config['embed_dim']}\")\n",
    "print(f\"  层数配置: {config['depths']}\")\n",
    "print(f\"  注意力头数: {config['num_heads']}\")\n",
    "print(f\"  窗口大小: {config['window_size']}\")\n",
    "\n",
    "# 测试前向传播\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = sample_batch_x[:2].to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"\\n🧪 前向传播测试:\")\n",
    "    print(f\"  输入形状: {test_input.shape}\")\n",
    "    print(f\"  输出形状: {test_output.shape}\")\n",
    "    print(f\"  输出数值范围: [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "\n",
    "print(\"\\n✅ Swin Transformer模型创建成功!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置损失函数\n",
    "if config['use_combined_loss']:\n",
    "    criterion = CombinedLoss(\n",
    "        alpha=data_info['class_weights'].to(device),\n",
    "        gamma=config['focal_gamma'],\n",
    "        label_smoothing=config['label_smoothing']\n",
    "    )\n",
    "    print(\"🎯 使用组合损失函数 (Focal + Dice + CrossEntropy)\")\nelse:\n    criterion = nn.CrossEntropyLoss(\n",
    "        weight=data_info['class_weights'].to(device),\n",
    "        label_smoothing=config['label_smoothing']\n",
    "    )\n    print(\"🎯 使用交叉熵损失函数\")\n",
    "\n",
    "# 配置优化器 - Swin Transformer专用参数\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "print(f\"⚙️ 优化器: AdamW (lr={config['learning_rate']}, wd={config['weight_decay']})\")\n",
    "\n",
    "# 配置学习率调度器\n",
    "if config['scheduler_type'] == 'cosine':\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,\n",
    "        T_mult=2,\n",
    "        eta_min=config['min_lr']\n",
    "    )\n",
    "    print(f\"📈 学习率调度器: CosineAnnealingWarmRestarts (min_lr={config['min_lr']})\")\nelse:\n    scheduler = None\n    print(\"📈 无学习率调度器\")\n",
    "\n",
    "# 混合精度训练\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler()\n",
    "print(\"⚡ 启用混合精度训练\")\n",
    "\n",
    "# 早停\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config['patience'],\n",
    "    verbose=True,\n",
    "    save_path=f\"{config['save_dir']}/best_model.pth\"\n",
    ")\n",
    "print(f\"⏹️ 早停机制 (patience={config['patience']})\")\n",
    "\n",
    "print(\"\\n✅ 训练组件配置完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🚀 训练准备（适配不同模式）\\nhistory = {\\n    'train_loss': [],\\n    'train_acc': [],\\n    'val_loss': [],\\n    'val_acc': [],\\n    'val_miou': [],\\n    'learning_rates': []\\n}\\n\\nbest_miou = 0.0\\nstart_time = time.time()\\n\\nif RUNNING_MODE == \\\"TEST\\\":\\n    print(f\\\"🧪 开始TEST模式训练 - Swin Transformer ({config['epochs']} epochs)\\\")\\n    print(f\\\"⚡ 目标: 快速验证代码正确性\\\")\\n    print(f\\\"🔧 模型配置: 轻量级 (embed_dim={config['embed_dim']}, depths={config['depths']})\\\")\\nelse:\\n    print(f\\\"🚀 开始TRAIN模式训练 - Swin Transformer ({config['epochs']} epochs)\\\")\\n    print(f\\\"🎯 目标: 获得最佳模型性能\\\")\\n    print(f\\\"💪 模型配置: 标准配置 (embed_dim={config['embed_dim']}, depths={config['depths']})\\\")\\n\\nprint(f\\\"⏰ 开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\")\\nprint(f\\\"🎯 特征: {config['depths']}层深度, {config['embed_dim']}嵌入维度, {config['window_size']}窗口大小\\\")\\nprint(\\\"=\\\" * 80)\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{config['epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 训练阶段\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, scaler, epoch,\n",
    "        scheduler=None,  # 我们手动调用scheduler\n",
    "        scheduler_step_per_batch=False,\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        max_grad_norm=config['max_grad_norm']\n",
    "    )\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_loss, val_acc, val_metrics = validate(\n",
    "        model, val_loader, criterion, device, data_info['num_classes']\n",
    "    )\n",
    "    \n",
    "    # 学习率调度\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # 获取当前学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_miou'].append(val_metrics['mean_iou'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # 计算epoch时间\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"Epoch {epoch} 结果:\")\n",
    "    print(f\"  训练 - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  验证 - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  验证 mIoU: {val_metrics['mean_iou']:.4f}\")\n",
    "    print(f\"  学习率: {current_lr:.2e}\")\n",
    "    print(f\"  耗时: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_metrics['mean_iou'] > best_miou:\n",
    "        best_miou = val_metrics['mean_iou']\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "            'scaler_state_dict': scaler.state_dict(),\n",
    "            'best_miou': best_miou,\n",
    "            'config': config,\n",
    "            'metrics': val_metrics\n",
    "        }, f\"{config['save_dir']}/best_model.pth\")\n",
    "        print(f\"  💾 新的最佳模型已保存! (mIoU: {best_miou:.4f})\")\n",
    "    \n",
    "    # 早停检查\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"\\n⏹️ 触发早停!\")\n",
    "        break\n",
    "    \n",
    "    # 每5个epoch显示一次进度\n",
    "    if epoch % 5 == 0:\n",
    "        total_time = time.time() - start_time\n",
    "        avg_epoch_time = total_time / epoch\n",
    "        estimated_total = avg_epoch_time * config['epochs']\n",
    "        print(f\"  📊 进度: {epoch/config['epochs']*100:.1f}%, 预计剩余时间: {(estimated_total - total_time)/60:.1f}分钟\")\n",
    "\n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"\\n🎉 Swin Transformer训练完成!\")\n",
    "print(f\"⏱️ 总训练时间: {total_training_time/60:.1f}分钟\")\n",
    "print(f\"🏆 最佳 mIoU: {best_miou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练历史\n",
    "with open(f\"{config['save_dir']}/history.json\", 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "print(\"💾 训练历史已保存\")\n",
    "\n",
    "# 绘制训练曲线\n",
    "plot_training_history(\n",
    "    history, \n",
    "    save_path=f\"{config['save_dir']}/training_curves.png\",\n",
    "    title=\"Swin Transformer Training History\"\n",
    ")\n",
    "\n",
    "print(\"📈 训练曲线已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型进行评估\n",
    "print(\"📂 加载最佳Swin Transformer模型进行评估...\")\n",
    "\n",
    "# 重新创建模型\n",
    "eval_model = create_swin_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['swin_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    depths=config['depths'],\n",
    "    num_heads=config['num_heads'],\n",
    "    window_size=config['window_size'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    drop_rate=config['dropout'],\n",
    "    attn_drop_rate=config['attn_dropout'],\n",
    "    drop_path_rate=0.0  # 评估时不使用drop_path\n",
    ").to(device)\n",
    "\n",
    "# 加载最佳权重\n",
    "checkpoint = load_checkpoint(f\"{config['save_dir']}/best_model.pth\", eval_model)\n",
    "eval_model.eval()\n",
    "\n",
    "print(f\"✅ 模型加载成功 (训练epoch: {checkpoint['epoch']})\")\n",
    "print(f\"🏆 训练时最佳mIoU: {checkpoint.get('best_miou', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估\n",
    "print(\"🧪 在测试集上评估Swin Transformer模型...\")\n",
    "\n",
    "eval_model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets_cpu = targets.numpy()\n",
    "        \n",
    "        outputs = eval_model(data)  # (batch, height, width, num_classes)\n",
    "        probs = torch.softmax(outputs, dim=-1)\n",
    "        _, predicted = outputs.max(-1)\n",
    "        \n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_targets.append(targets_cpu)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "# 合并所有批次\n",
    "all_preds = np.concatenate(all_preds).flatten()\n",
    "all_targets = np.concatenate(all_targets).flatten()\n",
    "\n",
    "# 计算详细指标\n",
    "metrics = calculate_metrics(all_preds, all_targets, data_info['num_classes'])\n",
    "metrics['class_names'] = data_info['class_names']\n",
    "\n",
    "print(f\"\\n📊 Swin Transformer测试集评估结果:\")\n",
    "print(f\"  总体准确率: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  平均准确率: {metrics['mean_accuracy']:.4f}\")\n",
    "print(f\"  平均IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  平均精确率: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  平均召回率: {metrics['mean_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示每个类别的详细指标\n",
    "print(f\"\\n📋 各类别详细指标 (Swin Transformer):\")\n",
    "print(f\"{'类别':<15} {'准确率':<10} {'IoU':<10} {'精确率':<10} {'召回率':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i in range(data_info['num_classes']):\n",
    "    class_name = data_info['class_names'][i]\n",
    "    acc = metrics['per_class_accuracy'][i]\n",
    "    iou = metrics['per_class_iou'][i]\n",
    "    precision = metrics['per_class_precision'][i]\n",
    "    recall = metrics['per_class_recall'][i]\n",
    "    \n",
    "    print(f\"{class_name:<15} {acc:<10.4f} {iou:<10.4f} {precision:<10.4f} {recall:<10.4f}\")\n",
    "\n",
    "# 找出表现最好和最差的类别\n",
    "best_class_idx = np.argmax(metrics['per_class_iou'])\n",
    "worst_class_idx = np.argmin(metrics['per_class_iou'])\n",
    "\n",
    "print(f\"\\n🥇 表现最好的类别: {data_info['class_names'][best_class_idx]} (IoU: {metrics['per_class_iou'][best_class_idx]:.4f})\")\n",
    "print(f\"🥉 表现最差的类别: {data_info['class_names'][worst_class_idx]} (IoU: {metrics['per_class_iou'][worst_class_idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "plot_confusion_matrix(\n",
    "    metrics['confusion_matrix'],\n",
    "    list(data_info['class_names'].values()),\n",
    "    save_path=f\"{config['save_dir']}/confusion_matrix.png\",\n",
    "    title=\"Swin Transformer Confusion Matrix\"\n",
    ")\n",
    "\n",
    "print(\"📊 混淆矩阵已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制类别性能图表\n",
    "plot_class_performance(\n",
    "    metrics, \n",
    "    save_path=f\"{config['save_dir']}/class_performance.png\",\n",
    "    title=\"Swin Transformer Per-Class Performance\"\n",
    ")\n",
    "\n",
    "print(\"📈 类别性能图表已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测结果\n",
    "print(\"🎨 生成Swin Transformer预测可视化...\")\n",
    "\n",
    "# 获取一批测试数据\n",
    "test_iter = iter(test_loader)\n",
    "test_batch_x, test_batch_y = next(test_iter)\n",
    "\n",
    "# 进行预测\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch_x_device = test_batch_x.to(device)\n",
    "    test_outputs = eval_model(test_batch_x_device)\n",
    "    _, test_predictions = test_outputs.max(-1)\n",
    "\n",
    "# 可视化预测结果\n",
    "visualize_predictions(\n",
    "    test_batch_x[:6],  # 显示6个样本\n",
    "    test_batch_y[:6],\n",
    "    test_predictions[:6].cpu(),\n",
    "    list(data_info['class_names'].values()),\n",
    "    num_samples=6,\n",
    "    save_path=f\"{config['save_dir']}/predictions_visualization.png\",\n",
    "    title=\"Swin Transformer Predictions vs Ground Truth\"\n",
    ")\n",
    "\n",
    "print(\"🖼️ 预测可视化已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 窗口注意力分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swin Transformer特有的窗口注意力分析\n",
    "print(\"🔍 分析Swin Transformer的窗口注意力模式...\")\n",
    "\n",
    "# 选择一个样本进行详细分析\n",
    "sample_idx = 0\n",
    "sample_input = test_batch_x[sample_idx:sample_idx+1].to(device)\n",
    "sample_target = test_batch_y[sample_idx]\n",
    "\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 获取预测\n",
    "    sample_output = eval_model(sample_input)\n",
    "    sample_probs = torch.softmax(sample_output, dim=-1)\n",
    "    confidence, prediction = sample_probs.max(-1)\n",
    "    \n",
    "    # 尝试获取patch embedding特征\n",
    "    try:\n",
    "        patch_features, (patch_h, patch_w) = eval_model.patch_embed(sample_input)\n",
    "        print(f\"✓ Patch features shape: {patch_features.shape}\")\n",
    "        print(f\"✓ Patch resolution: {patch_h} x {patch_w}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Cannot extract patch features: {e}\")\n",
    "        patch_features = None\n",
    "\n",
    "# 创建窗口分析可视化\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.suptitle('Swin Transformer Window Analysis', fontsize=16)\n",
    "\n",
    "# 原始RGB图像\n",
    "rgb_img = sample_input[0, :, :, 0, :3].cpu().numpy()\n",
    "rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "axes[0, 0].imshow(rgb_img)\n",
    "axes[0, 0].set_title('Input RGB (t=0)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 真实标签\n",
    "axes[0, 1].imshow(sample_target.numpy(), cmap='tab10')\n",
    "axes[0, 1].set_title('Ground Truth')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# 预测结果\n",
    "pred_img = prediction[0].cpu().numpy()\n",
    "axes[0, 2].imshow(pred_img, cmap='tab10')\n",
    "axes[0, 2].set_title('Swin Prediction')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# 预测置信度\n",
    "conf_img = confidence[0].cpu().numpy()\n",
    "im1 = axes[0, 3].imshow(conf_img, cmap='viridis')\n",
    "axes[0, 3].set_title('Prediction Confidence')\n",
    "axes[0, 3].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 3])\n",
    "\n",
    "# 窗口划分可视化\n",
    "window_size = config['window_size']\n",
    "H, W = sample_input.shape[1:3]\n",
    "\n",
    "# 创建窗口网格\n",
    "window_grid = np.zeros((H, W))\n",
    "window_id = 0\n",
    "for i in range(0, H, window_size):\n",
    "    for j in range(0, W, window_size):\n",
    "        end_i = min(i + window_size, H)\n",
    "        end_j = min(j + window_size, W)\n",
    "        window_grid[i:end_i, j:end_j] = window_id % 8  # 8种颜色循环\n",
    "        window_id += 1\n",
    "\n",
    "im2 = axes[1, 0].imshow(window_grid, cmap='Set3')\n",
    "axes[1, 0].set_title(f'Window Partition ({window_size}x{window_size})')\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1, 0])\n",
    "\n",
    "# patch特征可视化（如果可用）\n",
    "if patch_features is not None and patch_features.shape[1] > 0:\n",
    "    # 显示第一个特征通道\n",
    "    feature_map = patch_features[0, :, 0].view(patch_h, patch_w).cpu().numpy()\n",
    "    im3 = axes[1, 1].imshow(feature_map, cmap='coolwarm')\n",
    "    axes[1, 1].set_title('Patch Features (Channel 0)')\n",
    "    axes[1, 1].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[1, 1])\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Patch Features\\nNot Available', \n",
    "                   ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "# 计算样本准确率\n",
    "sample_accuracy = (pred_img == sample_target.numpy()).mean()\n",
    "\n",
    "# 类别分布\n",
    "unique, counts = np.unique(pred_img, return_counts=True)\n",
    "axes[1, 2].bar(unique, counts, color='lightblue', edgecolor='navy')\n",
    "axes[1, 2].set_xlabel('Class')\n",
    "axes[1, 2].set_ylabel('Pixel Count')\n",
    "axes[1, 2].set_title('Predicted Class Distribution')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 性能摘要\n",
    "axes[1, 3].text(0.1, 0.8, f'Sample Accuracy: {sample_accuracy:.3f}', transform=axes[1, 3].transAxes, fontsize=12)\n",
    "axes[1, 3].text(0.1, 0.7, f'Mean Confidence: {conf_img.mean():.3f}', transform=axes[1, 3].transAxes, fontsize=12)\n",
    "axes[1, 3].text(0.1, 0.6, f'Window Size: {window_size}x{window_size}', transform=axes[1, 3].transAxes, fontsize=12)\n",
    "axes[1, 3].text(0.1, 0.5, f'Embed Dim: {config[\"embed_dim\"]}', transform=axes[1, 3].transAxes, fontsize=12)\n",
    "axes[1, 3].text(0.1, 0.4, f'Depths: {config[\"depths\"]}', transform=axes[1, 3].transAxes, fontsize=12)\n",
    "axes[1, 3].set_title('Model Configuration')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['save_dir']}/window_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"🔍 窗口注意力分析完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示单个patch的推理\n",
    "print(\"🔮 演示Swin Transformer模型推理...\")\n",
    "\n",
    "# 获取一个样本\n",
    "sample_x = test_batch_x[0:1].to(device)  # 取第一个样本\n",
    "sample_y = test_batch_y[0:1]\n",
    "\n",
    "# 推理\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 前向传播\n",
    "    inference_start = time.time()\n",
    "    outputs = eval_model(sample_x)\n",
    "    inference_time = time.time() - inference_start\n",
    "    \n",
    "    # 获取预测和置信度\n",
    "    probs = torch.softmax(outputs, dim=-1)\n",
    "    confidence, predictions = probs.max(-1)\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = (predictions.cpu() == sample_y).float().mean().item()\n",
    "\n",
    "print(f\"\\n⚡ Swin Transformer推理性能:\")\n",
    "print(f\"  推理时间: {inference_time*1000:.2f}ms\")\n",
    "print(f\"  输入形状: {sample_x.shape}\")\n",
    "print(f\"  输出形状: {outputs.shape}\")\n",
    "print(f\"  预测准确率: {accuracy:.4f}\")\n",
    "print(f\"  平均置信度: {confidence.mean():.4f}\")\n",
    "print(f\"  最小置信度: {confidence.min():.4f}\")\n",
    "print(f\"  最大置信度: {confidence.max():.4f}\")\n",
    "print(f\"  窗口大小: {config['window_size']}x{config['window_size']}\")\n",
    "print(f\"  层次结构: {config['depths']} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化单个样本的推理结果和窗口分析\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Swin Transformer Single Sample Analysis', fontsize=16)\n",
    "\n",
    "# 原始RGB图像\n",
    "rgb_img = sample_x[0, :, :, 0, :3].cpu().numpy()\n",
    "rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "axes[0, 0].imshow(rgb_img)\n",
    "axes[0, 0].set_title('Input RGB (t=0)', fontsize=14)\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 真实标签\n",
    "gt_img = sample_y[0].numpy()\n",
    "im1 = axes[0, 1].imshow(gt_img, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[0, 1].set_title('Ground Truth', fontsize=14)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# 预测结果\n",
    "pred_img = predictions[0].cpu().numpy()\n",
    "im2 = axes[0, 2].imshow(pred_img, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[0, 2].set_title(f'Swin Prediction (Acc: {accuracy:.3f})', fontsize=14)\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# 置信度图\n",
    "conf_img = confidence[0].cpu().numpy()\n",
    "im3 = axes[1, 0].imshow(conf_img, cmap='viridis')\n",
    "axes[1, 0].set_title('Prediction Confidence', fontsize=14)\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im3, ax=axes[1, 0], label='Confidence')\n",
    "\n",
    "# 误差图（红色表示错误预测）\n",
    "error_map = (pred_img != gt_img).astype(float)\n",
    "im4 = axes[1, 1].imshow(error_map, cmap='Reds')\n",
    "axes[1, 1].set_title(f'Prediction Errors ({error_map.mean()*100:.1f}%)', fontsize=14)\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im4, ax=axes[1, 1], label='Error')\n",
    "\n",
    "# 置信度分布直方图\n",
    "axes[1, 2].hist(conf_img.flatten(), bins=30, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "axes[1, 2].axvline(conf_img.mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {conf_img.mean():.3f}')\n",
    "axes[1, 2].set_xlabel('Confidence')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].set_title('Confidence Distribution')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config['save_dir']}/single_sample_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"🎨 单样本Swin Transformer推理可视化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 🎯 Swin Transformer训练结果总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\\\"=\\\" * 80)\\nprint(f\\\"🎯 SWIN TRANSFORMER 农作物制图模型训练总结 ({RUNNING_MODE}模式)\\\")\\nprint(\\\"=\\\" * 80)\\n\\nprint(f\\\"\\\\n🔄 运行模式: {RUNNING_MODE}\\\")\\nif RUNNING_MODE == \\\"TEST\\\":\\n    print(\\\"  ✓ 快速验证代码正确性\\\")\\n    print(\\\"  ✓ 使用轻量级模型配置\\\")\\n    print(\\\"  ✓ 少量训练轮数\\\")\\n    print(\\\"  ✓ 适合本地开发环境\\\")\\nelse:\\n    print(\\\"  ✓ 完整训练流程\\\")\\n    print(\\\"  ✓ 标准模型配置\\\")\\n    print(\\\"  ✓ 充足训练轮数\\\")\\n    print(\\\"  ✓ 适合云端GPU环境\\\")\\n\\nprint(f\\\"\\\\n📊 模型配置:\\\")\\nprint(f\\\"  模型类型: Swin Transformer\\\")\\nprint(f\\\"  嵌入维度: {config['embed_dim']}\\\")\\nprint(f\\\"  层数配置: {config['depths']}\\\")\\nprint(f\\\"  注意力头数: {config['num_heads']}\\\")\\nprint(f\\\"  窗口大小: {config['window_size']}\\\")\\nprint(f\\\"  总参数量: {total_params:,}\\\")\\n\\nprint(f\\\"\\\\n🏃 训练过程:\\\")\\nprint(f\\\"  训练epochs: {len(history['train_loss'])}\\\")\\nprint(f\\\"  总训练时间: {total_training_time/60:.1f}分钟\\\")\\nprint(f\\\"  平均每epoch: {total_training_time/len(history['train_loss']):.1f}秒\\\")\\nprint(f\\\"  最佳验证mIoU: {best_miou:.4f}\\\")\\nif len(history['learning_rates']) > 0:\\n    print(f\\\"  最终学习率: {history['learning_rates'][-1]:.2e}\\\")\\n\\nprint(f\\\"\\\\n📈 最终性能:\\\")\\nprint(f\\\"  测试集总体准确率: {metrics['overall_accuracy']:.4f}\\\")\\nprint(f\\\"  测试集平均IoU: {metrics['mean_iou']:.4f}\\\")\\nprint(f\\\"  测试集平均精确率: {metrics['mean_precision']:.4f}\\\")\\nprint(f\\\"  测试集平均召回率: {metrics['mean_recall']:.4f}\\\")\\n\\nprint(f\\\"\\\\n🎯 Swin Transformer特色:\\\")\\nprint(f\\\"  ✓ 层次化特征提取: 4个阶段，分辨率逐步降低\\\")\\nprint(f\\\"  ✓ 移位窗口注意力: 建立跨窗口连接\\\")\\nprint(f\\\"  ✓ 线性复杂度: 相对于输入大小呈线性关系\\\")\\nprint(f\\\"  ✓ 多尺度融合: 通过Patch Merging实现特征融合\\\")\\n\\nprint(f\\\"\\\\n💾 保存的文件:\\\")\\nsave_dir = Path(config['save_dir'])\\nsaved_files = list(save_dir.glob('*'))\\nfor file in saved_files:\\n    print(f\\\"  {file.name}\\\")\\n\\nprint(f\\\"\\\\n🚀 使用建议:\\\")\\nif RUNNING_MODE == \\\"TEST\\\":\\n    print(f\\\"  ✅ 代码测试完成，可以切换到TRAIN模式进行完整训练\\\")\\n    print(f\\\"  📝 修改第一个cell: RUNNING_MODE = 'TRAIN'\\\")\\n    print(f\\\"  🔄 重新运行notebook进行完整训练\\\")\\n    print(f\\\"  ☁️ 建议在云端GPU上运行TRAIN模式\\\")\\nelse:\\n    print(f\\\"  1. 模型已保存到: {config['save_dir']}/best_model.pth\\\")\\n    print(f\\\"  2. 用于推理: python -m Swin-Transformer.inference --model-path {config['save_dir']}/best_model.pth\\\")\\n    print(f\\\"  3. 窗口分析: python -m Swin-Transformer.evaluate --analyze-windows\\\")\\n    print(f\\\"  4. 模型部署: 考虑导出为ONNX格式\\\")\\n\\nprint(f\\\"\\\\n📊 与其他模型对比:\\\")\\nprint(f\\\"  vs TCN: 更强的多尺度特征提取能力\\\")\\nprint(f\\\"  vs Vision Transformer: 更高的计算效率和更好的归纳偏置\\\")\\nprint(f\\\"  特点: 结合CNN的层次化设计和Transformer的全局建模能力\\\")\\n\\nprint(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\nif RUNNING_MODE == \\\"TEST\\\":\\n    print(\\\"🧪 Swin Transformer代码测试完成!\\\")\\n    print(\\\"✅ 所有组件运行正常，可以进行完整训练!\\\")\\nelse:\\n    print(\\\"🎉 Swin Transformer农作物制图模型训练完成!\\\")\\n    print(\\\"🌟 层次化窗口注意力，线性复杂度，SOTA性能!\\\")\\nprint(\\\"=\\\" * 80)\""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}