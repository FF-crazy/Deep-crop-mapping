{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Vision Transformer 农作物制图训练和评估\n\n本notebook演示如何使用Vision Transformer模型进行多光谱时序数据的农作物分类任务。\n\n## 🔄 双模式设计\n\n**📋 本notebook支持两种运行模式：**\n\n### 🧪 TEST模式 \n- **目的**: 本地快速测试代码正确性\n- **配置**: 轻量级模型，小数据集，少量epochs\n- **用时**: ~3分钟\n- **适用**: 开发调试，验证代码逻辑\n- **环境**: 本地CPU/GPU，低内存要求\n\n### 🚀 TRAIN模式\n- **目的**: 云端GPU完整训练获得最佳性能\n- **配置**: 标准模型，完整数据集，完整epochs\n- **用时**: ~8-16小时\n- **适用**: 正式训练，获得部署模型\n- **环境**: 云端GPU，高性能要求\n\n**💡 使用建议：**\n1. 本地开发时使用TEST模式验证代码\n2. 确认无误后切换到TRAIN模式进行完整训练\n3. 在云端GPU上运行TRAIN模式以获得最佳效果\n\n---\n\n## 目录\n1. [运行模式配置](#运行模式配置)\n2. [环境设置和导入](#环境设置和导入)\n3. [数据加载和探索](#数据加载和探索)\n4. [模型创建和配置](#模型创建和配置)\n5. [训练过程](#训练过程)\n6. [模型评估](#模型评估)\n7. [结果可视化](#结果可视化)\n8. [注意力机制分析](#注意力机制分析)\n9. [模型推理](#模型推理)\""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 🔧 运行模式配置\n# 设置 RUNNING_MODE 来选择运行模式\n# - \"TEST\": 本地测试模式，快速验证代码正确性\n# - \"TRAIN\": 云端训练模式，完整训练流程\n\nRUNNING_MODE = \"TEST\"  # 👈 修改这里来切换模式: \"TEST\" 或 \"TRAIN\"\n\nprint(f\"🔄 当前运行模式: {RUNNING_MODE}\")\n\nif RUNNING_MODE == \"TEST\":\n    print(\"🧪 TEST模式 - 用于本地测试:\")\n    print(\"  ✓ 使用小数据集\")\n    print(\"  ✓ 快速训练 (5 epochs)\")\n    print(\"  ✓ 小模型配置\")\n    print(\"  ✓ 快速验证代码正确性\")\nelif RUNNING_MODE == \"TRAIN\":\n    print(\"🚀 TRAIN模式 - 用于云端GPU训练:\")\n    print(\"  ✓ 使用完整数据集\")\n    print(\"  ✓ 完整训练 (100 epochs)\")\n    print(\"  ✓ 标准模型配置\")\n    print(\"  ✓ 最佳性能优化\")\nelse:\n    raise ValueError(\"RUNNING_MODE 必须是 'TEST' 或 'TRAIN'\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 2. 环境设置和导入",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch版本: 2.7.1\n",
      "CUDA可用: False\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置matplotlib中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU设备: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 3. 数据加载和探索"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 📋 根据运行模式配置参数\nif RUNNING_MODE == \"TEST\":\n    # 🧪 TEST模式配置 - 快速测试代码正确性\n    config = {\n        # 数据参数 - 使用更小的数据量\n        'data_path': '../dataset',\n        'patch_size': 32,     # 更小的patch大小\n        'stride': 16,         # 更小的stride，减少数据量\n        'test_size': 0.3,     # 更大的测试集比例\n        'val_size': 0.2,      # 更大的验证集比例\n        'batch_size': 2,      # 小batch size用于测试\n        'num_workers': 2,     # 少量工作进程\n        \n        # 模型参数 - 轻量级配置\n        'input_channels': 8,\n        'temporal_steps': 28,\n        'model_patch_size': 8,\n        'embed_dim': 128,     # 更小的嵌入维度\n        'num_layers': 3,      # 更少的层数\n        'num_heads': 4,       # 更少的注意力头\n        'mlp_ratio': 2.0,     # 更小的MLP比例\n        'dropout': 0.0,       # 简化配置\n        \n        # 训练参数 - 快速训练\n        'epochs': 5,          # 很少的epochs用于测试\n        'learning_rate': 1e-3, # 稍大的学习率快速收敛\n        'weight_decay': 0.01,\n        'gradient_accumulation_steps': 1,\n        'max_grad_norm': 1.0,\n        \n        # 损失函数\n        'use_combined_loss': False,  # 简单损失函数\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.05,\n        \n        # 学习率调度\n        'scheduler_type': 'none',  # 不使用调度器\n        'min_lr': 1e-5,\n        \n        # 其他\n        'patience': 5,        # 短耐心值\n        'save_dir': './checkpoints_test',\n        'augment_train': False  # 不使用数据增强\n    }\n    print(\"🧪 使用TEST模式配置 - 适合快速验证代码\")\n    \nelif RUNNING_MODE == \"TRAIN\":\n    # 🚀 TRAIN模式配置 - 完整训练流程\n    config = {\n        # 数据参数 - 使用完整数据集\n        'data_path': '../dataset',\n        'patch_size': 64,     # 标准patch大小\n        'stride': 32,         # 标准stride\n        'test_size': 0.2,\n        'val_size': 0.1,\n        'batch_size': 8,      # 适中的batch size\n        'num_workers': 4,\n        \n        # 模型参数 - 标准配置\n        'input_channels': 8,\n        'temporal_steps': 28,\n        'model_patch_size': 8,\n        'embed_dim': 256,     # 标准嵌入维度\n        'num_layers': 6,      # 标准层数\n        'num_heads': 8,       # 标准注意力头数\n        'mlp_ratio': 4.0,     # 标准MLP比例\n        'dropout': 0.1,\n        \n        # 训练参数 - 完整训练\n        'epochs': 100,        # 完整训练轮数\n        'learning_rate': 1e-4, # 标准学习率\n        'weight_decay': 1e-4,\n        'gradient_accumulation_steps': 2,\n        'max_grad_norm': 1.0,\n        \n        # 损失函数\n        'use_combined_loss': True,  # 使用组合损失\n        'focal_gamma': 2.5,\n        'label_smoothing': 0.1,\n        \n        # 学习率调度\n        'scheduler_type': 'cosine',\n        'min_lr': 1e-6,\n        \n        # 其他\n        'patience': 15,       # 长耐心值\n        'save_dir': './checkpoints_train',\n        'augment_train': True  # 使用数据增强\n    }\n    print(\"🚀 使用TRAIN模式配置 - 适合完整训练\")\n\n# 创建保存目录\nPath(config['save_dir']).mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\n📋 当前配置 ({RUNNING_MODE}模式):\")\nfor key, value in config.items():\n    print(f\"  {key}: {value}\")\n\nif RUNNING_MODE == \"TEST\":\n    print(\"\\n⚠️ 注意: TEST模式使用简化配置，仅用于验证代码正确性!\")\nelse:\n    print(\"\\n💪 TRAIN模式: 使用完整配置进行最佳性能训练!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🔄 加载和准备数据（适配不同模式）\nprint(f\"🔄 加载数据 ({RUNNING_MODE}模式)...\")\n\ntrain_loader, val_loader, test_loader, data_info = prepare_data(\n    data_path=config['data_path'],\n    patch_size=config['patch_size'],\n    stride=config['stride'],\n    test_size=config['test_size'],\n    val_size=config['val_size'],\n    batch_size=config['batch_size'],\n    num_workers=config['num_workers'],\n    augment_train=config['augment_train']\n)\n\nprint(f\"\\n📊 数据集信息 ({RUNNING_MODE}模式):\")\nprint(f\"  类别数量: {data_info['num_classes']}\")\nprint(f\"  训练批次: {len(train_loader)}\")\nprint(f\"  验证批次: {len(val_loader)}\")\nprint(f\"  测试批次: {len(test_loader)}\")\nprint(f\"  输入形状: {data_info['input_shape']}\")\n\n# 估算数据量\ntotal_train_samples = len(train_loader) * config['batch_size']\ntotal_val_samples = len(val_loader) * config['batch_size']\nprint(f\"  训练样本数: ~{total_train_samples}\")\nprint(f\"  验证样本数: ~{total_val_samples}\")\n\nif RUNNING_MODE == \"TEST\":\n    print(f\"\\n🧪 TEST模式数据量: 使用小数据集快速测试\")\n    print(f\"  预计单epoch时间: ~30秒\")\n    print(f\"  总训练时间: ~3分钟\")\nelse:\n    print(f\"\\n🚀 TRAIN模式数据量: 使用完整数据集\")\n    print(f\"  预计单epoch时间: ~5-10分钟\")\n    print(f\"  总训练时间: ~8-16小时\")\n\n# 保存数据信息\nsave_data_info(data_info, f\"{config['save_dir']}/data_info.pkl\")\n\n# 显示类别信息\nprint(f\"\\n🏷️ 类别信息:\")\nfor idx, name in data_info['class_names'].items():\n    print(f\"  {idx}: {name}\")\n\nprint(f\"\\n⚖️ 类别权重: {data_info['class_weights'].numpy()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 📋 根据运行模式配置参数\nif RUNNING_MODE == \"TEST\":\n    # 🧪 TEST模式配置 - 快速测试代码正确性\n    config = {\n        # 数据参数 - 使用更小的数据量\n        'data_path': '../dataset',\n        'patch_size': 32,     # 更小的patch大小\n        'stride': 16,         # 更小的stride，减少数据量\n        'test_size': 0.3,     # 更大的测试集比例\n        'val_size': 0.2,      # 更大的验证集比例\n        'batch_size': 2,      # 小batch size用于测试\n        'num_workers': 2,     # 少量工作进程\n        \n        # 模型参数 - 轻量级配置\n        'input_channels': 8,\n        'temporal_steps': 28,\n        'model_patch_size': 8,\n        'embed_dim': 128,     # 更小的嵌入维度\n        'num_layers': 3,      # 更少的层数\n        'num_heads': 4,       # 更少的注意力头\n        'mlp_ratio': 2.0,     # 更小的MLP比例\n        'dropout': 0.0,       # 简化配置\n        \n        # 训练参数 - 快速训练\n        'epochs': 5,          # 很少的epochs用于测试\n        'learning_rate': 1e-3, # 稍大的学习率快速收敛\n        'weight_decay': 0.01,\n        'gradient_accumulation_steps': 1,\n        'max_grad_norm': 1.0,\n        \n        # 损失函数\n        'use_combined_loss': False,  # 简单损失函数\n        'focal_gamma': 2.0,\n        'label_smoothing': 0.05,\n        \n        # 学习率调度\n        'scheduler_type': 'none',  # 不使用调度器\n        'min_lr': 1e-5,\n        \n        # 其他\n        'patience': 5,        # 短耐心值\n        'save_dir': '../Models/vision-transformer/test',  # 修改输出路径\n        'augment_train': False  # 不使用数据增强\n    }\n    print(\"🧪 使用TEST模式配置 - 适合快速验证代码\")\n    \nelif RUNNING_MODE == \"TRAIN\":\n    # 🚀 TRAIN模式配置 - 完整训练流程\n    config = {\n        # 数据参数 - 使用完整数据集\n        'data_path': '../dataset',\n        'patch_size': 64,     # 标准patch大小\n        'stride': 32,         # 标准stride\n        'test_size': 0.2,\n        'val_size': 0.1,\n        'batch_size': 8,      # 适中的batch size\n        'num_workers': 4,\n        \n        # 模型参数 - 标准配置\n        'input_channels': 8,\n        'temporal_steps': 28,\n        'model_patch_size': 8,\n        'embed_dim': 256,     # 标准嵌入维度\n        'num_layers': 6,      # 标准层数\n        'num_heads': 8,       # 标准注意力头数\n        'mlp_ratio': 4.0,     # 标准MLP比例\n        'dropout': 0.1,\n        \n        # 训练参数 - 完整训练\n        'epochs': 100,        # 完整训练轮数\n        'learning_rate': 1e-4, # 标准学习率\n        'weight_decay': 1e-4,\n        'gradient_accumulation_steps': 2,\n        'max_grad_norm': 1.0,\n        \n        # 损失函数\n        'use_combined_loss': True,  # 使用组合损失\n        'focal_gamma': 2.5,\n        'label_smoothing': 0.1,\n        \n        # 学习率调度\n        'scheduler_type': 'cosine',\n        'min_lr': 1e-6,\n        \n        # 其他\n        'patience': 15,       # 长耐心值\n        'save_dir': '../Models/vision-transformer/train',  # 修改输出路径\n        'augment_train': True  # 使用数据增强\n    }\n    print(\"🚀 使用TRAIN模式配置 - 适合完整训练\")\n\n# 创建保存目录\nPath(config['save_dir']).mkdir(parents=True, exist_ok=True)\n\nprint(f\"\\n📋 当前配置 ({RUNNING_MODE}模式):\")\nfor key, value in config.items():\n    print(f\"  {key}: {value}\")\n\nif RUNNING_MODE == \"TEST\":\n    print(\"\\n⚠️ 注意: TEST模式使用简化配置，仅用于验证代码正确性!\")\nelse:\n    print(\"\\n💪 TRAIN模式: 使用完整配置进行最佳性能训练!\")\n\nprint(f\"\\n💾 模型输出目录: {config['save_dir']}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 4. 模型创建和配置"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型创建和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"🖥️ 使用设备: {device}\")\n",
    "\n",
    "# 创建Transformer模型\n",
    "model = create_transformer_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['model_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# 计算参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n🔧 模型信息:\")\n",
    "print(f\"  总参数量: {total_params:,}\")\n",
    "print(f\"  可训练参数: {trainable_params:,}\")\n",
    "print(f\"  模型大小: {total_params * 4 / (1024**2):.1f} MB (FP32)\")\n",
    "\n",
    "# 测试前向传播\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = sample_batch_x[:2].to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"\\n🧪 前向传播测试:\")\n",
    "    print(f\"  输入形状: {test_input.shape}\")\n",
    "    print(f\"  输出形状: {test_output.shape}\")\n",
    "    print(f\"  输出数值范围: [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "\n",
    "print(\"\\n✅ 模型创建成功!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. 训练过程"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 🚀 训练准备（适配不同模式）\nhistory = {\n    'train_loss': [],\n    'train_acc': [],\n    'val_loss': [],\n    'val_acc': [],\n    'val_miou': [],\n    'learning_rates': []\n}\n\nbest_miou = 0.0\nstart_time = time.time()\n\nif RUNNING_MODE == \"TEST\":\n    print(f\"🧪 开始TEST模式训练 - Vision Transformer ({config['epochs']} epochs)\")\n    print(f\"⚡ 目标: 快速验证代码正确性\")\n    print(f\"🔧 模型配置: 轻量级 (embed_dim={config['embed_dim']}, layers={config['num_layers']})\")\nelse:\n    print(f\"🚀 开始TRAIN模式训练 - Vision Transformer ({config['epochs']} epochs)\")\n    print(f\"🎯 目标: 获得最佳模型性能\")\n    print(f\"💪 模型配置: 标准配置 (embed_dim={config['embed_dim']}, layers={config['num_layers']})\")\n\nprint(f\"⏰ 开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"🎯 特征: {config['num_layers']}层深度, {config['embed_dim']}嵌入维度, {config['num_heads']}注意力头\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练历史记录\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_miou': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_miou = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"🚀 开始训练 Transformer 模型 ({config['epochs']} epochs)\")\n",
    "print(f\"⏰ 开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{config['epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 训练阶段\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, scaler, epoch,\n",
    "        scheduler=None,  # 我们手动调用scheduler\n",
    "        scheduler_step_per_batch=False,\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        max_grad_norm=config['max_grad_norm']\n",
    "    )\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_loss, val_acc, val_metrics = validate(\n",
    "        model, val_loader, criterion, device, data_info['num_classes']\n",
    "    )\n",
    "    \n",
    "    # 学习率调度\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # 获取当前学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_miou'].append(val_metrics['mean_iou'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # 计算epoch时间\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"Epoch {epoch} 结果:\")\n",
    "    print(f\"  训练 - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  验证 - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  验证 mIoU: {val_metrics['mean_iou']:.4f}\")\n",
    "    print(f\"  学习率: {current_lr:.2e}\")\n",
    "    print(f\"  耗时: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_metrics['mean_iou'] > best_miou:\n",
    "        best_miou = val_metrics['mean_iou']\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "            'scaler_state_dict': scaler.state_dict(),\n",
    "            'best_miou': best_miou,\n",
    "            'config': config,\n",
    "            'metrics': val_metrics\n",
    "        }, f\"{config['save_dir']}/best_model.pth\")\n",
    "        print(f\"  💾 新的最佳模型已保存! (mIoU: {best_miou:.4f})\")\n",
    "    \n",
    "    # 早停检查\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"\\n⏹️ 触发早停!\")\n",
    "        break\n",
    "    \n",
    "    # 每5个epoch显示一次进度\n",
    "    if epoch % 5 == 0:\n",
    "        total_time = time.time() - start_time\n",
    "        avg_epoch_time = total_time / epoch\n",
    "        estimated_total = avg_epoch_time * config['epochs']\n",
    "        print(f\"  📊 进度: {epoch/config['epochs']*100:.1f}%, 预计剩余时间: {(estimated_total - total_time)/60:.1f}分钟\")\n",
    "\n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"\\n🎉 训练完成!\")\n",
    "print(f\"⏱️ 总训练时间: {total_training_time/60:.1f}分钟\")\n",
    "print(f\"🏆 最佳 mIoU: {best_miou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 6. 模型评估"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型进行评估\n",
    "print(\"📂 加载最佳模型进行评估...\")\n",
    "\n",
    "# 重新创建模型\n",
    "eval_model = create_transformer_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['model_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# 加载最佳权重\n",
    "checkpoint = load_checkpoint(f\"{config['save_dir']}/best_model.pth\", eval_model)\n",
    "eval_model.eval()\n",
    "\n",
    "print(f\"✅ 模型加载成功 (训练epoch: {checkpoint['epoch']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估\n",
    "print(\"🧪 在测试集上评估模型...\")\n",
    "\n",
    "eval_model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets_cpu = targets.numpy()\n",
    "        \n",
    "        outputs = eval_model(data)  # (batch, height, width, num_classes)\n",
    "        probs = torch.softmax(outputs, dim=-1)\n",
    "        _, predicted = outputs.max(-1)\n",
    "        \n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_targets.append(targets_cpu)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "# 合并所有批次\n",
    "all_preds = np.concatenate(all_preds).flatten()\n",
    "all_targets = np.concatenate(all_targets).flatten()\n",
    "\n",
    "# 计算详细指标\n",
    "metrics = calculate_metrics(all_preds, all_targets, data_info['num_classes'])\n",
    "metrics['class_names'] = data_info['class_names']\n",
    "\n",
    "print(f\"\\n📊 测试集评估结果:\")\n",
    "print(f\"  总体准确率: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  平均准确率: {metrics['mean_accuracy']:.4f}\")\n",
    "print(f\"  平均IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  平均精确率: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  平均召回率: {metrics['mean_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 7. 结果可视化"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "plot_confusion_matrix(\n",
    "    metrics['confusion_matrix'],\n",
    "    list(data_info['class_names'].values()),\n",
    "    save_path=f\"{config['save_dir']}/confusion_matrix.png\",\n",
    "    title=\"Transformer Confusion Matrix\"\n",
    ")\n",
    "\n",
    "print(\"📊 混淆矩阵已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制类别性能图表\n",
    "plot_class_performance(\n",
    "    metrics, \n",
    "    save_path=f\"{config['save_dir']}/class_performance.png\",\n",
    "    title=\"Transformer Per-Class Performance\"\n",
    ")\n",
    "\n",
    "print(\"📈 类别性能图表已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 8. 注意力机制分析"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示单个patch的推理\n",
    "print(\"🔮 演示模型推理...\")\n",
    "\n",
    "# 获取一个样本\n",
    "sample_x = test_batch_x[0:1].to(device)  # 取第一个样本\n",
    "sample_y = test_batch_y[0:1]\n",
    "\n",
    "# 推理\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 前向传播\n",
    "    inference_start = time.time()\n",
    "    outputs = eval_model(sample_x)\n",
    "    inference_time = time.time() - inference_start\n",
    "    \n",
    "    # 获取预测和置信度\n",
    "    probs = torch.softmax(outputs, dim=-1)\n",
    "    confidence, predictions = probs.max(-1)\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = (predictions.cpu() == sample_y).float().mean().item()\n",
    "\n",
    "print(f\"\\n⚡ 推理性能:\")\n",
    "print(f\"  推理时间: {inference_time*1000:.2f}ms\")\n",
    "print(f\"  输入形状: {sample_x.shape}\")\n",
    "print(f\"  输出形状: {outputs.shape}\")\n",
    "print(f\"  预测准确率: {accuracy:.4f}\")\n",
    "print(f\"  平均置信度: {confidence.mean():.4f}\")\n",
    "print(f\"  最小置信度: {confidence.min():.4f}\")\n",
    "print(f\"  最大置信度: {confidence.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 9. 模型推理"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(\"=\" * 80)\nprint(f\"🎯 VISION TRANSFORMER 农作物制图模型训练总结 ({RUNNING_MODE}模式)\")\nprint(\"=\" * 80)\n\nprint(f\"\\n🔄 运行模式: {RUNNING_MODE}\")\nif RUNNING_MODE == \"TEST\":\n    print(\"  ✓ 快速验证代码正确性\")\n    print(\"  ✓ 使用轻量级模型配置\")\n    print(\"  ✓ 少量训练轮数\")\n    print(\"  ✓ 适合本地开发环境\")\nelse:\n    print(\"  ✓ 完整训练流程\")\n    print(\"  ✓ 标准模型配置\")\n    print(\"  ✓ 充足训练轮数\")\n    print(\"  ✓ 适合云端GPU环境\")\n\nprint(f\"\\n📊 模型配置:\")\nprint(f\"  模型类型: Vision Transformer\")\nprint(f\"  嵌入维度: {config['embed_dim']}\")\nprint(f\"  层数: {config['num_layers']}\")\nprint(f\"  注意力头数: {config['num_heads']}\")\nprint(f\"  Patch大小: {config['model_patch_size']}x{config['model_patch_size']}\")\nprint(f\"  总参数量: {total_params:,}\")\n\nprint(f\"\\n🏃 训练过程:\")\nprint(f\"  训练epochs: {len(history['train_loss'])}\")\nprint(f\"  总训练时间: {total_training_time/60:.1f}分钟\")\nprint(f\"  平均每epoch: {total_training_time/len(history['train_loss']):.1f}秒\")\nprint(f\"  最佳验证mIoU: {best_miou:.4f}\")\nif len(history['learning_rates']) > 0:\n    print(f\"  最终学习率: {history['learning_rates'][-1]:.2e}\")\n\nprint(f\"\\n📈 最终性能:\")\nprint(f\"  测试集总体准确率: {metrics['overall_accuracy']:.4f}\")\nprint(f\"  测试集平均IoU: {metrics['mean_iou']:.4f}\")\nprint(f\"  测试集平均精确率: {metrics['mean_precision']:.4f}\")\nprint(f\"  测试集平均召回率: {metrics['mean_recall']:.4f}\")\n\nprint(f\"\\n🎯 Vision Transformer特色:\")\nprint(f\"  ✓ 全局自注意力机制: 建立长程依赖关系\")\nprint(f\"  ✓ 位置编码: 提供空间位置信息\")\nprint(f\"  ✓ 多头注意力: 捕获不同类型的特征关系\")\nprint(f\"  ✓ 时空融合: 有效处理多光谱时序数据\")\n\nprint(f\"\\n💾 保存的文件:\")\nsave_dir = Path(config['save_dir'])\nsaved_files = list(save_dir.glob('*'))\nfor file in saved_files:\n    print(f\"  {file.name}\")\n\nprint(f\"\\n🚀 使用建议:\")\nif RUNNING_MODE == \"TEST\":\n    print(f\"  ✅ 代码测试完成，可以切换到TRAIN模式进行完整训练\")\n    print(f\"  📝 修改第一个cell: RUNNING_MODE = 'TRAIN'\")\n    print(f\"  🔄 重新运行notebook进行完整训练\")\n    print(f\"  ☁️ 建议在云端GPU上运行TRAIN模式\")\nelse:\n    print(f\"  1. 模型已保存到: {config['save_dir']}/best_model.pth\")\n    print(f\"  2. 用于推理: python -m Transformer.inference --model-path {config['save_dir']}/best_model.pth\")\n    print(f\"  3. 注意力分析: 可视化注意力权重分布\")\n    print(f\"  4. 模型部署: 考虑导出为ONNX格式\")\n\nprint(f\"\\n📊 与其他模型对比:\")\nprint(f\"  vs TCN: 更强的全局建模能力\")\nprint(f\"  vs Swin Transformer: 更直接的全局注意力但计算复杂度更高\")\nprint(f\"  特点: 纯注意力机制，强大的特征学习能力\")\n\nprint(\"\\n\" + \"=\" * 80)\nif RUNNING_MODE == \"TEST\":\n    print(\"🧪 Vision Transformer代码测试完成!\")\n    print(\"✅ 所有组件运行正常，可以进行完整训练!\")\nelse:\n    print(\"🎉 Vision Transformer农作物制图模型训练完成!\")\n    print(\"🌟 全局自注意力，强大特征学习，优秀泛化性能!\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"🎯 TRANSFORMER 农作物制图模型训练总结\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n📊 模型配置:\")\n",
    "print(f\"  模型类型: Vision Transformer\")\n",
    "print(f\"  嵌入维度: {config['embed_dim']}\")\n",
    "print(f\"  层数: {config['num_layers']}\")\n",
    "print(f\"  注意力头数: {config['num_heads']}\")\n",
    "print(f\"  总参数量: {total_params:,}\")\n",
    "\n",
    "print(f\"\\n🏃 训练过程:\")\n",
    "print(f\"  训练epochs: {len(history['train_loss'])}\")\n",
    "print(f\"  总训练时间: {total_training_time/60:.1f}分钟\")\n",
    "print(f\"  平均每epoch: {total_training_time/len(history['train_loss']):.1f}秒\")\n",
    "print(f\"  最佳验证mIoU: {best_miou:.4f}\")\n",
    "\n",
    "print(f\"\\n📈 最终性能:\")\n",
    "print(f\"  测试集总体准确率: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  测试集平均IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  测试集平均精确率: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  测试集平均召回率: {metrics['mean_recall']:.4f}\")\n",
    "\n",
    "print(f\"\\n💾 保存的文件:\")\n",
    "save_dir = Path(config['save_dir'])\n",
    "saved_files = list(save_dir.glob('*'))\n",
    "for file in saved_files:\n",
    "    print(f\"  {file.name}\")\n",
    "\n",
    "print(f\"\\n🚀 使用建议:\")\n",
    "print(f\"  1. 模型已保存到: {config['save_dir']}/best_model.pth\")\n",
    "print(f\"  2. 用于推理: python -m Transformer.inference --model-path {config['save_dir']}/best_model.pth\")\n",
    "print(f\"  3. 继续训练: 加载checkpoint并调整学习率\")\n",
    "print(f\"  4. 模型部署: 考虑量化或剪枝以减少计算需求\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎉 Transformer农作物制图模型训练完成!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepCropMapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}