{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer å†œä½œç‰©åˆ¶å›¾è®­ç»ƒå’Œè¯„ä¼°\n",
    "\n",
    "æœ¬notebookæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Vision Transformeræ¨¡å‹è¿›è¡Œå¤šå…‰è°±æ—¶åºæ•°æ®çš„å†œä½œç‰©åˆ†ç±»ä»»åŠ¡ã€‚\n",
    "\n",
    "## ç›®å½•\n",
    "1. [ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥](#ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥)\n",
    "2. [æ•°æ®åŠ è½½å’Œæ¢ç´¢](#æ•°æ®åŠ è½½å’Œæ¢ç´¢)\n",
    "3. [æ¨¡å‹åˆ›å»ºå’Œé…ç½®](#æ¨¡å‹åˆ›å»ºå’Œé…ç½®)\n",
    "4. [è®­ç»ƒè¿‡ç¨‹](#è®­ç»ƒè¿‡ç¨‹)\n",
    "5. [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)\n",
    "6. [ç»“æœå¯è§†åŒ–](#ç»“æœå¯è§†åŒ–)\n",
    "7. [æ¨¡å‹æ¨ç†](#æ¨¡å‹æ¨ç†)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchç‰ˆæœ¬: 2.7.1\n",
      "CUDAå¯ç”¨: False\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transformeræ¨¡å—å¯¼å…¥æˆåŠŸ!\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥Transformeræ¨¡å—\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from Transformer.model import create_transformer_model, CropMappingTransformer\n",
    "from Transformer.dataset import prepare_data, save_data_info, load_data_info\n",
    "from Transformer.train import (\n",
    "    train_epoch, validate, FocalLoss, DiceLoss, CombinedLoss\n",
    ")\n",
    "from Transformer.utils import (\n",
    "    save_checkpoint, load_checkpoint, EarlyStopping,\n",
    "    calculate_metrics, plot_training_history, plot_class_performance,\n",
    "    plot_confusion_matrix, visualize_predictions\n",
    ")\n",
    "\n",
    "print(\"âœ… Transformeræ¨¡å—å¯¼å…¥æˆåŠŸ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ•°æ®åŠ è½½å’Œæ¢ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ è®­ç»ƒé…ç½®:\n",
      "  data_path: ../dataset\n",
      "  patch_size: 64\n",
      "  stride: 32\n",
      "  test_size: 0.2\n",
      "  val_size: 0.1\n",
      "  batch_size: 8\n",
      "  num_workers: 4\n",
      "  input_channels: 8\n",
      "  temporal_steps: 28\n",
      "  model_patch_size: 8\n",
      "  embed_dim: 256\n",
      "  num_layers: 6\n",
      "  num_heads: 8\n",
      "  mlp_ratio: 4.0\n",
      "  dropout: 0.1\n",
      "  epochs: 50\n",
      "  learning_rate: 0.0001\n",
      "  weight_decay: 0.0001\n",
      "  gradient_accumulation_steps: 2\n",
      "  max_grad_norm: 1.0\n",
      "  use_combined_loss: True\n",
      "  focal_gamma: 2.5\n",
      "  label_smoothing: 0.1\n",
      "  scheduler_type: cosine\n",
      "  min_lr: 1e-06\n",
      "  patience: 10\n",
      "  save_dir: ./checkpoints_notebook\n",
      "  augment_train: True\n"
     ]
    }
   ],
   "source": [
    "# é…ç½®å‚æ•°\n",
    "config = {\n",
    "    # æ•°æ®å‚æ•°\n",
    "    'data_path': '../dataset',\n",
    "    'patch_size': 64,\n",
    "    'stride': 32,\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'batch_size': 8,  # Transformeré€šå¸¸éœ€è¦è¾ƒå°çš„batch size\n",
    "    'num_workers': 4,\n",
    "    \n",
    "    # æ¨¡å‹å‚æ•°\n",
    "    'input_channels': 8,\n",
    "    'temporal_steps': 28,\n",
    "    'model_patch_size': 8,  # Transformerçš„patchå¤§å°\n",
    "    'embed_dim': 256,\n",
    "    'num_layers': 6,\n",
    "    'num_heads': 8,\n",
    "    'mlp_ratio': 4.0,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    # è®­ç»ƒå‚æ•°\n",
    "    'epochs': 50,  # æ¼”ç¤ºç”¨è¾ƒå°‘epochs\n",
    "    'learning_rate': 1e-4,  # Transformeré€šå¸¸ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡\n",
    "    'weight_decay': 1e-4,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'max_grad_norm': 1.0,\n",
    "    \n",
    "    # æŸå¤±å‡½æ•°\n",
    "    'use_combined_loss': True,\n",
    "    'focal_gamma': 2.5,\n",
    "    'label_smoothing': 0.1,\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦\n",
    "    'scheduler_type': 'cosine',\n",
    "    'min_lr': 1e-6,\n",
    "    \n",
    "    # å…¶ä»–\n",
    "    'patience': 10,\n",
    "    'save_dir': './checkpoints_notebook',\n",
    "    'augment_train': True\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¿å­˜ç›®å½•\n",
    "Path(config['save_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“‹ è®­ç»ƒé…ç½®:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½å’Œå‡†å¤‡æ•°æ®\n",
    "print(\"ğŸ”„ åŠ è½½æ•°æ®...\")\n",
    "train_loader, val_loader, test_loader, data_info = prepare_data(\n",
    "    data_path=config['data_path'],\n",
    "    patch_size=config['patch_size'],\n",
    "    stride=config['stride'],\n",
    "    test_size=config['test_size'],\n",
    "    val_size=config['val_size'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    augment_train=config['augment_train']\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:\")\n",
    "print(f\"  ç±»åˆ«æ•°é‡: {data_info['num_classes']}\")\n",
    "print(f\"  è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}\")\n",
    "print(f\"  éªŒè¯æ‰¹æ¬¡: {len(val_loader)}\")\n",
    "print(f\"  æµ‹è¯•æ‰¹æ¬¡: {len(test_loader)}\")\n",
    "print(f\"  è¾“å…¥å½¢çŠ¶: {data_info['input_shape']}\")\n",
    "\n",
    "# ä¿å­˜æ•°æ®ä¿¡æ¯\n",
    "save_data_info(data_info, f\"{config['save_dir']}/data_info.pkl\")\n",
    "\n",
    "# æ˜¾ç¤ºç±»åˆ«ä¿¡æ¯\n",
    "print(f\"\\nğŸ·ï¸ ç±»åˆ«ä¿¡æ¯:\")\n",
    "for idx, name in data_info['class_names'].items():\n",
    "    print(f\"  {idx}: {name}\")\n",
    "\n",
    "print(f\"\\nâš–ï¸ ç±»åˆ«æƒé‡: {data_info['class_weights'].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¯è§†åŒ–\n",
    "# è·å–ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®è¿›è¡Œå¯è§†åŒ–\n",
    "data_iter = iter(train_loader)\n",
    "sample_batch_x, sample_batch_y = next(data_iter)\n",
    "\n",
    "print(f\"æ ·æœ¬æ‰¹æ¬¡å½¢çŠ¶ - X: {sample_batch_x.shape}, Y: {sample_batch_y.shape}\")\n",
    "print(f\"Xæ•°å€¼èŒƒå›´: [{sample_batch_x.min():.3f}, {sample_batch_x.max():.3f}]\")\n",
    "print(f\"Yå”¯ä¸€å€¼: {torch.unique(sample_batch_y)}\")\n",
    "\n",
    "# å¯è§†åŒ–å‡ ä¸ªæ ·æœ¬\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(8, sample_batch_x.shape[0])):\n",
    "    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„RGBåˆæˆå›¾åƒ\n",
    "    rgb_img = sample_batch_x[i, :, :, 0, :3].numpy()\n",
    "    rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "    \n",
    "    axes[i].imshow(rgb_img)\n",
    "    axes[i].set_title(f'Sample {i+1} - RGB (t=0)')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# å¯è§†åŒ–å¯¹åº”çš„æ ‡ç­¾\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(8, sample_batch_y.shape[0])):\n",
    "    im = axes[i].imshow(sample_batch_y[i].numpy(), cmap='tab10', vmin=0, vmax=7)\n",
    "    axes[i].set_title(f'Sample {i+1} - Labels')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¨¡å‹åˆ›å»ºå’Œé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®è®¾å¤‡\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# åˆ›å»ºTransformeræ¨¡å‹\n",
    "model = create_transformer_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['model_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# è®¡ç®—å‚æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nğŸ”§ æ¨¡å‹ä¿¡æ¯:\")\n",
    "print(f\"  æ€»å‚æ•°é‡: {total_params:,}\")\n",
    "print(f\"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "print(f\"  æ¨¡å‹å¤§å°: {total_params * 4 / (1024**2):.1f} MB (FP32)\")\n",
    "\n",
    "# æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = sample_batch_x[:2].to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"\\nğŸ§ª å‰å‘ä¼ æ’­æµ‹è¯•:\")\n",
    "    print(f\"  è¾“å…¥å½¢çŠ¶: {test_input.shape}\")\n",
    "    print(f\"  è¾“å‡ºå½¢çŠ¶: {test_output.shape}\")\n",
    "    print(f\"  è¾“å‡ºæ•°å€¼èŒƒå›´: [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "\n",
    "print(\"\\nâœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®æŸå¤±å‡½æ•°\n",
    "if config['use_combined_loss']:\n",
    "    criterion = CombinedLoss(\n",
    "        alpha=data_info['class_weights'].to(device),\n",
    "        gamma=config['focal_gamma'],\n",
    "        label_smoothing=config['label_smoothing']\n",
    "    )\n",
    "    print(\"ğŸ¯ ä½¿ç”¨ç»„åˆæŸå¤±å‡½æ•° (Focal + Dice + CrossEntropy)\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        weight=data_info['class_weights'].to(device),\n",
    "        label_smoothing=config['label_smoothing']\n",
    "    )\n",
    "    print(\"ğŸ¯ ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°\")\n",
    "\n",
    "# é…ç½®ä¼˜åŒ–å™¨\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "print(f\"âš™ï¸ ä¼˜åŒ–å™¨: AdamW (lr={config['learning_rate']}, wd={config['weight_decay']})\")\n",
    "\n",
    "# é…ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "if config['scheduler_type'] == 'cosine':\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,\n",
    "        T_mult=2,\n",
    "        eta_min=config['min_lr']\n",
    "    )\n",
    "    print(f\"ğŸ“ˆ å­¦ä¹ ç‡è°ƒåº¦å™¨: CosineAnnealingWarmRestarts\")\n",
    "else:\n",
    "    scheduler = None\n",
    "    print(\"ğŸ“ˆ æ— å­¦ä¹ ç‡è°ƒåº¦å™¨\")\n",
    "\n",
    "# æ··åˆç²¾åº¦è®­ç»ƒ\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler()\n",
    "print(\"âš¡ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ\")\n",
    "\n",
    "# æ—©åœ\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config['patience'],\n",
    "    verbose=True,\n",
    "    save_path=f\"{config['save_dir']}/best_model.pth\"\n",
    ")\n",
    "print(f\"â¹ï¸ æ—©åœæœºåˆ¶ (patience={config['patience']})\")\n",
    "\n",
    "print(\"\\nâœ… è®­ç»ƒç»„ä»¶é…ç½®å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è®­ç»ƒè¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå†å²è®°å½•\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_miou': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_miou = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ Transformer æ¨¡å‹ ({config['epochs']} epochs)\")\n",
    "print(f\"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå¾ªç¯\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{config['epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # è®­ç»ƒé˜¶æ®µ\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, scaler, epoch,\n",
    "        scheduler=None,  # æˆ‘ä»¬æ‰‹åŠ¨è°ƒç”¨scheduler\n",
    "        scheduler_step_per_batch=False,\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        max_grad_norm=config['max_grad_norm']\n",
    "    )\n",
    "    \n",
    "    # éªŒè¯é˜¶æ®µ\n",
    "    val_loss, val_acc, val_metrics = validate(\n",
    "        model, val_loader, criterion, device, data_info['num_classes']\n",
    "    )\n",
    "    \n",
    "    # å­¦ä¹ ç‡è°ƒåº¦\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # è·å–å½“å‰å­¦ä¹ ç‡\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # è®°å½•å†å²\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_miou'].append(val_metrics['mean_iou'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # è®¡ç®—epochæ—¶é—´\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # æ‰“å°ç»“æœ\n",
    "    print(f\"Epoch {epoch} ç»“æœ:\")\n",
    "    print(f\"  è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  éªŒè¯ mIoU: {val_metrics['mean_iou']:.4f}\")\n",
    "    print(f\"  å­¦ä¹ ç‡: {current_lr:.2e}\")\n",
    "    print(f\"  è€—æ—¶: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "    if val_metrics['mean_iou'] > best_miou:\n",
    "        best_miou = val_metrics['mean_iou']\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "            'scaler_state_dict': scaler.state_dict(),\n",
    "            'best_miou': best_miou,\n",
    "            'config': config,\n",
    "            'metrics': val_metrics\n",
    "        }, f\"{config['save_dir']}/best_model.pth\")\n",
    "        print(f\"  ğŸ’¾ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜! (mIoU: {best_miou:.4f})\")\n",
    "    \n",
    "    # æ—©åœæ£€æŸ¥\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"\\nâ¹ï¸ è§¦å‘æ—©åœ!\")\n",
    "        break\n",
    "    \n",
    "    # æ¯5ä¸ªepochæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦\n",
    "    if epoch % 5 == 0:\n",
    "        total_time = time.time() - start_time\n",
    "        avg_epoch_time = total_time / epoch\n",
    "        estimated_total = avg_epoch_time * config['epochs']\n",
    "        print(f\"  ğŸ“Š è¿›åº¦: {epoch/config['epochs']*100:.1f}%, é¢„è®¡å‰©ä½™æ—¶é—´: {(estimated_total - total_time)/60:.1f}åˆ†é’Ÿ\")\n",
    "\n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"\\nğŸ‰ è®­ç»ƒå®Œæˆ!\")\n",
    "print(f\"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.1f}åˆ†é’Ÿ\")\n",
    "print(f\"ğŸ† æœ€ä½³ mIoU: {best_miou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜è®­ç»ƒå†å²\n",
    "with open(f\"{config['save_dir']}/history.json\", 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "print(\"ğŸ’¾ è®­ç»ƒå†å²å·²ä¿å­˜\")\n",
    "\n",
    "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
    "plot_training_history(\n",
    "    history, \n",
    "    save_path=f\"{config['save_dir']}/training_curves.png\",\n",
    "    title=\"Transformer Training History\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¨¡å‹è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°\n",
    "print(\"ğŸ“‚ åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°...\")\n",
    "\n",
    "# é‡æ–°åˆ›å»ºæ¨¡å‹\n",
    "eval_model = create_transformer_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['model_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# åŠ è½½æœ€ä½³æƒé‡\n",
    "checkpoint = load_checkpoint(f\"{config['save_dir']}/best_model.pth\", eval_model)\n",
    "eval_model.eval()\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è®­ç»ƒepoch: {checkpoint['epoch']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "print(\"ğŸ§ª åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...\")\n",
    "\n",
    "eval_model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets_cpu = targets.numpy()\n",
    "        \n",
    "        outputs = eval_model(data)  # (batch, height, width, num_classes)\n",
    "        probs = torch.softmax(outputs, dim=-1)\n",
    "        _, predicted = outputs.max(-1)\n",
    "        \n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_targets.append(targets_cpu)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡\n",
    "all_preds = np.concatenate(all_preds).flatten()\n",
    "all_targets = np.concatenate(all_targets).flatten()\n",
    "\n",
    "# è®¡ç®—è¯¦ç»†æŒ‡æ ‡\n",
    "metrics = calculate_metrics(all_preds, all_targets, data_info['num_classes'])\n",
    "metrics['class_names'] = data_info['class_names']\n",
    "\n",
    "print(f\"\\nğŸ“Š æµ‹è¯•é›†è¯„ä¼°ç»“æœ:\")\n",
    "print(f\"  æ€»ä½“å‡†ç¡®ç‡: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  å¹³å‡å‡†ç¡®ç‡: {metrics['mean_accuracy']:.4f}\")\n",
    "print(f\"  å¹³å‡IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  å¹³å‡ç²¾ç¡®ç‡: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  å¹³å‡å¬å›ç‡: {metrics['mean_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡\n",
    "print(f\"\\nğŸ“‹ å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:\")\n",
    "print(f\"{'ç±»åˆ«':<15} {'å‡†ç¡®ç‡':<10} {'IoU':<10} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(data_info['num_classes']):\n",
    "    class_name = data_info['class_names'][i]\n",
    "    acc = metrics['per_class_accuracy'][i]\n",
    "    iou = metrics['per_class_iou'][i]\n",
    "    precision = metrics['per_class_precision'][i]\n",
    "    recall = metrics['per_class_recall'][i]\n",
    "    \n",
    "    print(f\"{class_name:<15} {acc:<10.4f} {iou:<10.4f} {precision:<10.4f} {recall:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç»“æœå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "plot_confusion_matrix(\n",
    "    metrics['confusion_matrix'],\n",
    "    list(data_info['class_names'].values()),\n",
    "    save_path=f\"{config['save_dir']}/confusion_matrix.png\",\n",
    "    title=\"Transformer Confusion Matrix\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»˜åˆ¶ç±»åˆ«æ€§èƒ½å›¾è¡¨\n",
    "plot_class_performance(\n",
    "    metrics, \n",
    "    save_path=f\"{config['save_dir']}/class_performance.png\",\n",
    "    title=\"Transformer Per-Class Performance\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ˆ ç±»åˆ«æ€§èƒ½å›¾è¡¨å·²ä¿å­˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
    "print(\"ğŸ¨ ç”Ÿæˆé¢„æµ‹å¯è§†åŒ–...\")\n",
    "\n",
    "# è·å–ä¸€æ‰¹æµ‹è¯•æ•°æ®\n",
    "test_iter = iter(test_loader)\n",
    "test_batch_x, test_batch_y = next(test_iter)\n",
    "\n",
    "# è¿›è¡Œé¢„æµ‹\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch_x_device = test_batch_x.to(device)\n",
    "    test_outputs = eval_model(test_batch_x_device)\n",
    "    _, test_predictions = test_outputs.max(-1)\n",
    "\n",
    "# å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
    "visualize_predictions(\n",
    "    test_batch_x[:6],  # æ˜¾ç¤º6ä¸ªæ ·æœ¬\n",
    "    test_batch_y[:6],\n",
    "    test_predictions[:6].cpu(),\n",
    "    list(data_info['class_names'].values()),\n",
    "    num_samples=6,\n",
    "    save_path=f\"{config['save_dir']}/predictions_visualization.png\",\n",
    "    title=\"Transformer Predictions vs Ground Truth\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ–¼ï¸ é¢„æµ‹å¯è§†åŒ–å·²ä¿å­˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ¨¡å‹æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºå•ä¸ªpatchçš„æ¨ç†\n",
    "print(\"ğŸ”® æ¼”ç¤ºæ¨¡å‹æ¨ç†...\")\n",
    "\n",
    "# è·å–ä¸€ä¸ªæ ·æœ¬\n",
    "sample_x = test_batch_x[0:1].to(device)  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "sample_y = test_batch_y[0:1]\n",
    "\n",
    "# æ¨ç†\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    # å‰å‘ä¼ æ’­\n",
    "    inference_start = time.time()\n",
    "    outputs = eval_model(sample_x)\n",
    "    inference_time = time.time() - inference_start\n",
    "    \n",
    "    # è·å–é¢„æµ‹å’Œç½®ä¿¡åº¦\n",
    "    probs = torch.softmax(outputs, dim=-1)\n",
    "    confidence, predictions = probs.max(-1)\n",
    "    \n",
    "    # è®¡ç®—å‡†ç¡®ç‡\n",
    "    accuracy = (predictions.cpu() == sample_y).float().mean().item()\n",
    "\n",
    "print(f\"\\nâš¡ æ¨ç†æ€§èƒ½:\")\n",
    "print(f\"  æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms\")\n",
    "print(f\"  è¾“å…¥å½¢çŠ¶: {sample_x.shape}\")\n",
    "print(f\"  è¾“å‡ºå½¢çŠ¶: {outputs.shape}\")\n",
    "print(f\"  é¢„æµ‹å‡†ç¡®ç‡: {accuracy:.4f}\")\n",
    "print(f\"  å¹³å‡ç½®ä¿¡åº¦: {confidence.mean():.4f}\")\n",
    "print(f\"  æœ€å°ç½®ä¿¡åº¦: {confidence.min():.4f}\")\n",
    "print(f\"  æœ€å¤§ç½®ä¿¡åº¦: {confidence.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„æ¨ç†ç»“æœ\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# åŸå§‹RGBå›¾åƒ\n",
    "rgb_img = sample_x[0, :, :, 0, :3].cpu().numpy()\n",
    "rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "axes[0].imshow(rgb_img)\n",
    "axes[0].set_title('Input RGB (t=0)', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# çœŸå®æ ‡ç­¾\n",
    "gt_img = sample_y[0].numpy()\n",
    "im1 = axes[1].imshow(gt_img, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[1].set_title('Ground Truth', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# é¢„æµ‹ç»“æœ\n",
    "pred_img = predictions[0].cpu().numpy()\n",
    "im2 = axes[2].imshow(pred_img, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[2].set_title(f'Prediction (Acc: {accuracy:.3f})', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# ç½®ä¿¡åº¦å›¾\n",
    "conf_img = confidence[0].cpu().numpy()\n",
    "im3 = axes[3].imshow(conf_img, cmap='viridis')\n",
    "axes[3].set_title('Confidence Map', fontsize=14)\n",
    "axes[3].axis('off')\n",
    "plt.colorbar(im3, ax=axes[3], label='Confidence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ¨ å•æ ·æœ¬æ¨ç†å¯è§†åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "### ğŸ¯ è®­ç»ƒç»“æœæ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ğŸ¯ TRANSFORMER å†œä½œç‰©åˆ¶å›¾æ¨¡å‹è®­ç»ƒæ€»ç»“\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“Š æ¨¡å‹é…ç½®:\")\n",
    "print(f\"  æ¨¡å‹ç±»å‹: Vision Transformer\")\n",
    "print(f\"  åµŒå…¥ç»´åº¦: {config['embed_dim']}\")\n",
    "print(f\"  å±‚æ•°: {config['num_layers']}\")\n",
    "print(f\"  æ³¨æ„åŠ›å¤´æ•°: {config['num_heads']}\")\n",
    "print(f\"  æ€»å‚æ•°é‡: {total_params:,}\")\n",
    "\n",
    "print(f\"\\nğŸƒ è®­ç»ƒè¿‡ç¨‹:\")\n",
    "print(f\"  è®­ç»ƒepochs: {len(history['train_loss'])}\")\n",
    "print(f\"  æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.1f}åˆ†é’Ÿ\")\n",
    "print(f\"  å¹³å‡æ¯epoch: {total_training_time/len(history['train_loss']):.1f}ç§’\")\n",
    "print(f\"  æœ€ä½³éªŒè¯mIoU: {best_miou:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æœ€ç»ˆæ€§èƒ½:\")\n",
    "print(f\"  æµ‹è¯•é›†æ€»ä½“å‡†ç¡®ç‡: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  æµ‹è¯•é›†å¹³å‡IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  æµ‹è¯•é›†å¹³å‡ç²¾ç¡®ç‡: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  æµ‹è¯•é›†å¹³å‡å¬å›ç‡: {metrics['mean_recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ä¿å­˜çš„æ–‡ä»¶:\")\n",
    "save_dir = Path(config['save_dir'])\n",
    "saved_files = list(save_dir.glob('*'))\n",
    "for file in saved_files:\n",
    "    print(f\"  {file.name}\")\n",
    "\n",
    "print(f\"\\nğŸš€ ä½¿ç”¨å»ºè®®:\")\n",
    "print(f\"  1. æ¨¡å‹å·²ä¿å­˜åˆ°: {config['save_dir']}/best_model.pth\")\n",
    "print(f\"  2. ç”¨äºæ¨ç†: python -m Transformer.inference --model-path {config['save_dir']}/best_model.pth\")\n",
    "print(f\"  3. ç»§ç»­è®­ç»ƒ: åŠ è½½checkpointå¹¶è°ƒæ•´å­¦ä¹ ç‡\")\n",
    "print(f\"  4. æ¨¡å‹éƒ¨ç½²: è€ƒè™‘é‡åŒ–æˆ–å‰ªæä»¥å‡å°‘è®¡ç®—éœ€æ±‚\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ‰ Transformerå†œä½œç‰©åˆ¶å›¾æ¨¡å‹è®­ç»ƒå®Œæˆ!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepCropMapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
