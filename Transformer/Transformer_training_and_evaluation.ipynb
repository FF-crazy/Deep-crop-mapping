{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer 农作物制图训练和评估\n",
    "\n",
    "本notebook演示如何使用Vision Transformer模型进行多光谱时序数据的农作物分类任务。\n",
    "\n",
    "## 目录\n",
    "1. [环境设置和导入](#环境设置和导入)\n",
    "2. [数据加载和探索](#数据加载和探索)\n",
    "3. [模型创建和配置](#模型创建和配置)\n",
    "4. [训练过程](#训练过程)\n",
    "5. [模型评估](#模型评估)\n",
    "6. [结果可视化](#结果可视化)\n",
    "7. [模型推理](#模型推理)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch版本: 2.7.1\n",
      "CUDA可用: False\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置matplotlib中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU设备: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformer模块导入成功!\n"
     ]
    }
   ],
   "source": [
    "# 导入Transformer模块\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from Transformer.model import create_transformer_model, CropMappingTransformer\n",
    "from Transformer.dataset import prepare_data, save_data_info, load_data_info\n",
    "from Transformer.train import (\n",
    "    train_epoch, validate, FocalLoss, DiceLoss, CombinedLoss\n",
    ")\n",
    "from Transformer.utils import (\n",
    "    save_checkpoint, load_checkpoint, EarlyStopping,\n",
    "    calculate_metrics, plot_training_history, plot_class_performance,\n",
    "    plot_confusion_matrix, visualize_predictions\n",
    ")\n",
    "\n",
    "print(\"✅ Transformer模块导入成功!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载和探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 训练配置:\n",
      "  data_path: ../dataset\n",
      "  patch_size: 64\n",
      "  stride: 32\n",
      "  test_size: 0.2\n",
      "  val_size: 0.1\n",
      "  batch_size: 8\n",
      "  num_workers: 4\n",
      "  input_channels: 8\n",
      "  temporal_steps: 28\n",
      "  model_patch_size: 8\n",
      "  embed_dim: 256\n",
      "  num_layers: 6\n",
      "  num_heads: 8\n",
      "  mlp_ratio: 4.0\n",
      "  dropout: 0.1\n",
      "  epochs: 50\n",
      "  learning_rate: 0.0001\n",
      "  weight_decay: 0.0001\n",
      "  gradient_accumulation_steps: 2\n",
      "  max_grad_norm: 1.0\n",
      "  use_combined_loss: True\n",
      "  focal_gamma: 2.5\n",
      "  label_smoothing: 0.1\n",
      "  scheduler_type: cosine\n",
      "  min_lr: 1e-06\n",
      "  patience: 10\n",
      "  save_dir: ./checkpoints_notebook\n",
      "  augment_train: True\n"
     ]
    }
   ],
   "source": [
    "# 配置参数\n",
    "config = {\n",
    "    # 数据参数\n",
    "    'data_path': '../dataset',\n",
    "    'patch_size': 64,\n",
    "    'stride': 32,\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'batch_size': 8,  # Transformer通常需要较小的batch size\n",
    "    'num_workers': 4,\n",
    "    \n",
    "    # 模型参数\n",
    "    'input_channels': 8,\n",
    "    'temporal_steps': 28,\n",
    "    'model_patch_size': 8,  # Transformer的patch大小\n",
    "    'embed_dim': 256,\n",
    "    'num_layers': 6,\n",
    "    'num_heads': 8,\n",
    "    'mlp_ratio': 4.0,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    # 训练参数\n",
    "    'epochs': 50,  # 演示用较少epochs\n",
    "    'learning_rate': 1e-4,  # Transformer通常使用较小的学习率\n",
    "    'weight_decay': 1e-4,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'max_grad_norm': 1.0,\n",
    "    \n",
    "    # 损失函数\n",
    "    'use_combined_loss': True,\n",
    "    'focal_gamma': 2.5,\n",
    "    'label_smoothing': 0.1,\n",
    "    \n",
    "    # 学习率调度\n",
    "    'scheduler_type': 'cosine',\n",
    "    'min_lr': 1e-6,\n",
    "    \n",
    "    # 其他\n",
    "    'patience': 10,\n",
    "    'save_dir': './checkpoints_notebook',\n",
    "    'augment_train': True\n",
    "}\n",
    "\n",
    "# 创建保存目录\n",
    "Path(config['save_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"📋 训练配置:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载和准备数据\n",
    "print(\"🔄 加载数据...\")\n",
    "train_loader, val_loader, test_loader, data_info = prepare_data(\n",
    "    data_path=config['data_path'],\n",
    "    patch_size=config['patch_size'],\n",
    "    stride=config['stride'],\n",
    "    test_size=config['test_size'],\n",
    "    val_size=config['val_size'],\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    augment_train=config['augment_train']\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 数据集信息:\")\n",
    "print(f\"  类别数量: {data_info['num_classes']}\")\n",
    "print(f\"  训练批次: {len(train_loader)}\")\n",
    "print(f\"  验证批次: {len(val_loader)}\")\n",
    "print(f\"  测试批次: {len(test_loader)}\")\n",
    "print(f\"  输入形状: {data_info['input_shape']}\")\n",
    "\n",
    "# 保存数据信息\n",
    "save_data_info(data_info, f\"{config['save_dir']}/data_info.pkl\")\n",
    "\n",
    "# 显示类别信息\n",
    "print(f\"\\n🏷️ 类别信息:\")\n",
    "for idx, name in data_info['class_names'].items():\n",
    "    print(f\"  {idx}: {name}\")\n",
    "\n",
    "print(f\"\\n⚖️ 类别权重: {data_info['class_weights'].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "# 获取一个批次的数据进行可视化\n",
    "data_iter = iter(train_loader)\n",
    "sample_batch_x, sample_batch_y = next(data_iter)\n",
    "\n",
    "print(f\"样本批次形状 - X: {sample_batch_x.shape}, Y: {sample_batch_y.shape}\")\n",
    "print(f\"X数值范围: [{sample_batch_x.min():.3f}, {sample_batch_x.max():.3f}]\")\n",
    "print(f\"Y唯一值: {torch.unique(sample_batch_y)}\")\n",
    "\n",
    "# 可视化几个样本\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(8, sample_batch_x.shape[0])):\n",
    "    # 显示第一个时间步的RGB合成图像\n",
    "    rgb_img = sample_batch_x[i, :, :, 0, :3].numpy()\n",
    "    rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "    \n",
    "    axes[i].imshow(rgb_img)\n",
    "    axes[i].set_title(f'Sample {i+1} - RGB (t=0)')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 可视化对应的标签\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(8, sample_batch_y.shape[0])):\n",
    "    im = axes[i].imshow(sample_batch_y[i].numpy(), cmap='tab10', vmin=0, vmax=7)\n",
    "    axes[i].set_title(f'Sample {i+1} - Labels')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型创建和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"🖥️ 使用设备: {device}\")\n",
    "\n",
    "# 创建Transformer模型\n",
    "model = create_transformer_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['model_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# 计算参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n🔧 模型信息:\")\n",
    "print(f\"  总参数量: {total_params:,}\")\n",
    "print(f\"  可训练参数: {trainable_params:,}\")\n",
    "print(f\"  模型大小: {total_params * 4 / (1024**2):.1f} MB (FP32)\")\n",
    "\n",
    "# 测试前向传播\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = sample_batch_x[:2].to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"\\n🧪 前向传播测试:\")\n",
    "    print(f\"  输入形状: {test_input.shape}\")\n",
    "    print(f\"  输出形状: {test_output.shape}\")\n",
    "    print(f\"  输出数值范围: [{test_output.min():.3f}, {test_output.max():.3f}]\")\n",
    "\n",
    "print(\"\\n✅ 模型创建成功!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置损失函数\n",
    "if config['use_combined_loss']:\n",
    "    criterion = CombinedLoss(\n",
    "        alpha=data_info['class_weights'].to(device),\n",
    "        gamma=config['focal_gamma'],\n",
    "        label_smoothing=config['label_smoothing']\n",
    "    )\n",
    "    print(\"🎯 使用组合损失函数 (Focal + Dice + CrossEntropy)\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        weight=data_info['class_weights'].to(device),\n",
    "        label_smoothing=config['label_smoothing']\n",
    "    )\n",
    "    print(\"🎯 使用交叉熵损失函数\")\n",
    "\n",
    "# 配置优化器\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "print(f\"⚙️ 优化器: AdamW (lr={config['learning_rate']}, wd={config['weight_decay']})\")\n",
    "\n",
    "# 配置学习率调度器\n",
    "if config['scheduler_type'] == 'cosine':\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,\n",
    "        T_mult=2,\n",
    "        eta_min=config['min_lr']\n",
    "    )\n",
    "    print(f\"📈 学习率调度器: CosineAnnealingWarmRestarts\")\n",
    "else:\n",
    "    scheduler = None\n",
    "    print(\"📈 无学习率调度器\")\n",
    "\n",
    "# 混合精度训练\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler()\n",
    "print(\"⚡ 启用混合精度训练\")\n",
    "\n",
    "# 早停\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config['patience'],\n",
    "    verbose=True,\n",
    "    save_path=f\"{config['save_dir']}/best_model.pth\"\n",
    ")\n",
    "print(f\"⏹️ 早停机制 (patience={config['patience']})\")\n",
    "\n",
    "print(\"\\n✅ 训练组件配置完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练历史记录\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_miou': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_miou = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"🚀 开始训练 Transformer 模型 ({config['epochs']} epochs)\")\n",
    "print(f\"⏰ 开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{config['epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 训练阶段\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, scaler, epoch,\n",
    "        scheduler=None,  # 我们手动调用scheduler\n",
    "        scheduler_step_per_batch=False,\n",
    "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "        max_grad_norm=config['max_grad_norm']\n",
    "    )\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_loss, val_acc, val_metrics = validate(\n",
    "        model, val_loader, criterion, device, data_info['num_classes']\n",
    "    )\n",
    "    \n",
    "    # 学习率调度\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # 获取当前学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_miou'].append(val_metrics['mean_iou'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # 计算epoch时间\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"Epoch {epoch} 结果:\")\n",
    "    print(f\"  训练 - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  验证 - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  验证 mIoU: {val_metrics['mean_iou']:.4f}\")\n",
    "    print(f\"  学习率: {current_lr:.2e}\")\n",
    "    print(f\"  耗时: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_metrics['mean_iou'] > best_miou:\n",
    "        best_miou = val_metrics['mean_iou']\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "            'scaler_state_dict': scaler.state_dict(),\n",
    "            'best_miou': best_miou,\n",
    "            'config': config,\n",
    "            'metrics': val_metrics\n",
    "        }, f\"{config['save_dir']}/best_model.pth\")\n",
    "        print(f\"  💾 新的最佳模型已保存! (mIoU: {best_miou:.4f})\")\n",
    "    \n",
    "    # 早停检查\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"\\n⏹️ 触发早停!\")\n",
    "        break\n",
    "    \n",
    "    # 每5个epoch显示一次进度\n",
    "    if epoch % 5 == 0:\n",
    "        total_time = time.time() - start_time\n",
    "        avg_epoch_time = total_time / epoch\n",
    "        estimated_total = avg_epoch_time * config['epochs']\n",
    "        print(f\"  📊 进度: {epoch/config['epochs']*100:.1f}%, 预计剩余时间: {(estimated_total - total_time)/60:.1f}分钟\")\n",
    "\n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"\\n🎉 训练完成!\")\n",
    "print(f\"⏱️ 总训练时间: {total_training_time/60:.1f}分钟\")\n",
    "print(f\"🏆 最佳 mIoU: {best_miou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练历史\n",
    "with open(f\"{config['save_dir']}/history.json\", 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "print(\"💾 训练历史已保存\")\n",
    "\n",
    "# 绘制训练曲线\n",
    "plot_training_history(\n",
    "    history, \n",
    "    save_path=f\"{config['save_dir']}/training_curves.png\",\n",
    "    title=\"Transformer Training History\"\n",
    ")\n",
    "\n",
    "print(\"📈 训练曲线已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型进行评估\n",
    "print(\"📂 加载最佳模型进行评估...\")\n",
    "\n",
    "# 重新创建模型\n",
    "eval_model = create_transformer_model(\n",
    "    input_channels=config['input_channels'],\n",
    "    temporal_steps=config['temporal_steps'],\n",
    "    num_classes=data_info['num_classes'],\n",
    "    patch_size=config['model_patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "# 加载最佳权重\n",
    "checkpoint = load_checkpoint(f\"{config['save_dir']}/best_model.pth\", eval_model)\n",
    "eval_model.eval()\n",
    "\n",
    "print(f\"✅ 模型加载成功 (训练epoch: {checkpoint['epoch']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估\n",
    "print(\"🧪 在测试集上评估模型...\")\n",
    "\n",
    "eval_model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets_cpu = targets.numpy()\n",
    "        \n",
    "        outputs = eval_model(data)  # (batch, height, width, num_classes)\n",
    "        probs = torch.softmax(outputs, dim=-1)\n",
    "        _, predicted = outputs.max(-1)\n",
    "        \n",
    "        all_preds.append(predicted.cpu().numpy())\n",
    "        all_targets.append(targets_cpu)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "# 合并所有批次\n",
    "all_preds = np.concatenate(all_preds).flatten()\n",
    "all_targets = np.concatenate(all_targets).flatten()\n",
    "\n",
    "# 计算详细指标\n",
    "metrics = calculate_metrics(all_preds, all_targets, data_info['num_classes'])\n",
    "metrics['class_names'] = data_info['class_names']\n",
    "\n",
    "print(f\"\\n📊 测试集评估结果:\")\n",
    "print(f\"  总体准确率: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  平均准确率: {metrics['mean_accuracy']:.4f}\")\n",
    "print(f\"  平均IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  平均精确率: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  平均召回率: {metrics['mean_recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示每个类别的详细指标\n",
    "print(f\"\\n📋 各类别详细指标:\")\n",
    "print(f\"{'类别':<15} {'准确率':<10} {'IoU':<10} {'精确率':<10} {'召回率':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(data_info['num_classes']):\n",
    "    class_name = data_info['class_names'][i]\n",
    "    acc = metrics['per_class_accuracy'][i]\n",
    "    iou = metrics['per_class_iou'][i]\n",
    "    precision = metrics['per_class_precision'][i]\n",
    "    recall = metrics['per_class_recall'][i]\n",
    "    \n",
    "    print(f\"{class_name:<15} {acc:<10.4f} {iou:<10.4f} {precision:<10.4f} {recall:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "plot_confusion_matrix(\n",
    "    metrics['confusion_matrix'],\n",
    "    list(data_info['class_names'].values()),\n",
    "    save_path=f\"{config['save_dir']}/confusion_matrix.png\",\n",
    "    title=\"Transformer Confusion Matrix\"\n",
    ")\n",
    "\n",
    "print(\"📊 混淆矩阵已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制类别性能图表\n",
    "plot_class_performance(\n",
    "    metrics, \n",
    "    save_path=f\"{config['save_dir']}/class_performance.png\",\n",
    "    title=\"Transformer Per-Class Performance\"\n",
    ")\n",
    "\n",
    "print(\"📈 类别性能图表已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测结果\n",
    "print(\"🎨 生成预测可视化...\")\n",
    "\n",
    "# 获取一批测试数据\n",
    "test_iter = iter(test_loader)\n",
    "test_batch_x, test_batch_y = next(test_iter)\n",
    "\n",
    "# 进行预测\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_batch_x_device = test_batch_x.to(device)\n",
    "    test_outputs = eval_model(test_batch_x_device)\n",
    "    _, test_predictions = test_outputs.max(-1)\n",
    "\n",
    "# 可视化预测结果\n",
    "visualize_predictions(\n",
    "    test_batch_x[:6],  # 显示6个样本\n",
    "    test_batch_y[:6],\n",
    "    test_predictions[:6].cpu(),\n",
    "    list(data_info['class_names'].values()),\n",
    "    num_samples=6,\n",
    "    save_path=f\"{config['save_dir']}/predictions_visualization.png\",\n",
    "    title=\"Transformer Predictions vs Ground Truth\"\n",
    ")\n",
    "\n",
    "print(\"🖼️ 预测可视化已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示单个patch的推理\n",
    "print(\"🔮 演示模型推理...\")\n",
    "\n",
    "# 获取一个样本\n",
    "sample_x = test_batch_x[0:1].to(device)  # 取第一个样本\n",
    "sample_y = test_batch_y[0:1]\n",
    "\n",
    "# 推理\n",
    "eval_model.eval()\n",
    "with torch.no_grad():\n",
    "    # 前向传播\n",
    "    inference_start = time.time()\n",
    "    outputs = eval_model(sample_x)\n",
    "    inference_time = time.time() - inference_start\n",
    "    \n",
    "    # 获取预测和置信度\n",
    "    probs = torch.softmax(outputs, dim=-1)\n",
    "    confidence, predictions = probs.max(-1)\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = (predictions.cpu() == sample_y).float().mean().item()\n",
    "\n",
    "print(f\"\\n⚡ 推理性能:\")\n",
    "print(f\"  推理时间: {inference_time*1000:.2f}ms\")\n",
    "print(f\"  输入形状: {sample_x.shape}\")\n",
    "print(f\"  输出形状: {outputs.shape}\")\n",
    "print(f\"  预测准确率: {accuracy:.4f}\")\n",
    "print(f\"  平均置信度: {confidence.mean():.4f}\")\n",
    "print(f\"  最小置信度: {confidence.min():.4f}\")\n",
    "print(f\"  最大置信度: {confidence.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化单个样本的推理结果\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# 原始RGB图像\n",
    "rgb_img = sample_x[0, :, :, 0, :3].cpu().numpy()\n",
    "rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "axes[0].imshow(rgb_img)\n",
    "axes[0].set_title('Input RGB (t=0)', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 真实标签\n",
    "gt_img = sample_y[0].numpy()\n",
    "im1 = axes[1].imshow(gt_img, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[1].set_title('Ground Truth', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 预测结果\n",
    "pred_img = predictions[0].cpu().numpy()\n",
    "im2 = axes[2].imshow(pred_img, cmap='tab10', vmin=0, vmax=7)\n",
    "axes[2].set_title(f'Prediction (Acc: {accuracy:.3f})', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 置信度图\n",
    "conf_img = confidence[0].cpu().numpy()\n",
    "im3 = axes[3].imshow(conf_img, cmap='viridis')\n",
    "axes[3].set_title('Confidence Map', fontsize=14)\n",
    "axes[3].axis('off')\n",
    "plt.colorbar(im3, ax=axes[3], label='Confidence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🎨 单样本推理可视化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 🎯 训练结果总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"🎯 TRANSFORMER 农作物制图模型训练总结\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n📊 模型配置:\")\n",
    "print(f\"  模型类型: Vision Transformer\")\n",
    "print(f\"  嵌入维度: {config['embed_dim']}\")\n",
    "print(f\"  层数: {config['num_layers']}\")\n",
    "print(f\"  注意力头数: {config['num_heads']}\")\n",
    "print(f\"  总参数量: {total_params:,}\")\n",
    "\n",
    "print(f\"\\n🏃 训练过程:\")\n",
    "print(f\"  训练epochs: {len(history['train_loss'])}\")\n",
    "print(f\"  总训练时间: {total_training_time/60:.1f}分钟\")\n",
    "print(f\"  平均每epoch: {total_training_time/len(history['train_loss']):.1f}秒\")\n",
    "print(f\"  最佳验证mIoU: {best_miou:.4f}\")\n",
    "\n",
    "print(f\"\\n📈 最终性能:\")\n",
    "print(f\"  测试集总体准确率: {metrics['overall_accuracy']:.4f}\")\n",
    "print(f\"  测试集平均IoU: {metrics['mean_iou']:.4f}\")\n",
    "print(f\"  测试集平均精确率: {metrics['mean_precision']:.4f}\")\n",
    "print(f\"  测试集平均召回率: {metrics['mean_recall']:.4f}\")\n",
    "\n",
    "print(f\"\\n💾 保存的文件:\")\n",
    "save_dir = Path(config['save_dir'])\n",
    "saved_files = list(save_dir.glob('*'))\n",
    "for file in saved_files:\n",
    "    print(f\"  {file.name}\")\n",
    "\n",
    "print(f\"\\n🚀 使用建议:\")\n",
    "print(f\"  1. 模型已保存到: {config['save_dir']}/best_model.pth\")\n",
    "print(f\"  2. 用于推理: python -m Transformer.inference --model-path {config['save_dir']}/best_model.pth\")\n",
    "print(f\"  3. 继续训练: 加载checkpoint并调整学习率\")\n",
    "print(f\"  4. 模型部署: 考虑量化或剪枝以减少计算需求\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎉 Transformer农作物制图模型训练完成!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepCropMapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
